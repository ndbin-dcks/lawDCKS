import streamlit as st
from openai import OpenAI
import requests
from datetime import datetime
from urllib.parse import quote
import os
import re

# Cáº¥u hÃ¬nh trang
st.set_page_config(
    page_title="âš–ï¸ Trá»£ lÃ½ PhÃ¡p cháº¿ KhoÃ¡ng sáº£n Viá»‡t Nam",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Model pricing (USD per 1K tokens)
MODEL_PRICING = {
    "gpt-4o-mini": {"input": 0.00015, "output": 0.0006},
    "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002},
    "gpt-4": {"input": 0.03, "output": 0.06},
    "gpt-4-turbo-preview": {"input": 0.01, "output": 0.03}
}

def init_session_state():
    """Khá»Ÿi táº¡o session state"""
    if "token_stats" not in st.session_state:
        st.session_state.token_stats = {
            "total_input_tokens": 0,
            "total_output_tokens": 0,
            "total_cost": 0.0,
            "session_start": datetime.now(),
            "request_count": 0
        }
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": get_system_prompt()},
            {"role": "assistant", "content": get_welcome_message()}
        ]

def safe_get_stats():
    """Láº¥y thá»‘ng kÃª an toÃ n"""
    init_session_state()
    stats = st.session_state.token_stats
    total_tokens = stats["total_input_tokens"] + stats["total_output_tokens"]
    return {
        "total_tokens": total_tokens,
        "input_tokens": stats["total_input_tokens"],
        "output_tokens": stats["total_output_tokens"],
        "total_cost_usd": stats["total_cost"],
        "total_cost_vnd": stats["total_cost"] * 24000,
        "requests": stats["request_count"],
        "session_duration": datetime.now() - stats["session_start"]
    }

def update_stats(input_tokens, output_tokens, model):
    """Cáº­p nháº­t thá»‘ng kÃª"""
    init_session_state()
    if model not in MODEL_PRICING:
        model = "gpt-4o-mini"
    pricing = MODEL_PRICING[model]
    cost = (input_tokens / 1000) * pricing["input"] + (output_tokens / 1000) * pricing["output"]
    st.session_state.token_stats["total_input_tokens"] += input_tokens
    st.session_state.token_stats["total_output_tokens"] += output_tokens
    st.session_state.token_stats["total_cost"] += cost
    st.session_state.token_stats["request_count"] += 1

def count_tokens(text):
    """Æ¯á»›c tÃ­nh sá»‘ token"""
    return len(str(text)) // 4

def get_system_prompt():
    """Láº¥y system prompt"""
    try:
        with open("01.system_trainning.txt", "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        return """Báº¡n lÃ  chuyÃªn gia phÃ¡p cháº¿ vá» khoÃ¡ng sáº£n táº¡i Viá»‡t Nam. 
- Chá»‰ tráº£ lá»i cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n khoÃ¡ng sáº£n.
- ÄÆ°a ra thÃ´ng tin chÃ­nh xÃ¡c, trÃ­ch dáº«n Ä‘iá»u luáº­t cá»¥ thá»ƒ.
- Giáº£i thÃ­ch rÃµ rÃ ng, dá»… hiá»ƒu.
- Æ¯u tiÃªn nguá»“n chÃ­nh thá»‘ng: vbpl.vn, thuvienphapluat.vn, monre.gov.vn, chinhphu.vn.
- Tá»« chá»‘i lá»‹ch sá»± cÃ¡c cÃ¢u há»i khÃ´ng liÃªn quan.
- TrÃ­ch dáº«n: Ghi rÃµ vÄƒn báº£n, Ä‘iá»u, khoáº£n; Ä‘á» xuáº¥t kiá»ƒm tra vbpl.vn náº¿u khÃ´ng cháº¯c cháº¯n."""

def get_welcome_message():
    """Láº¥y tin nháº¯n chÃ o"""
    try:
        with open("02.assistant.txt", "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        return """âš–ï¸ Xin chÃ o! TÃ´i lÃ  Trá»£ lÃ½ PhÃ¡p cháº¿ KhoÃ¡ng sáº£n Viá»‡t Nam.
Há»— trá»£: Luáº­t KhoÃ¡ng sáº£n, thá»§ tá»¥c cáº¥p phÃ©p, thuáº¿ phÃ­, xá»­ pháº¡t vi pháº¡m.
Há»i tÃ´i vá» khoÃ¡ng sáº£n nhÃ©! ğŸ¤” Kiá»ƒm tra thÃ´ng tin táº¡i vbpl.vn."""

def get_default_model():
    """Láº¥y model máº·c Ä‘á»‹nh"""
    try:
        with open("module_chatgpt.txt", "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "gpt-4o-mini"

def is_mineral_related(message):
    """Kiá»ƒm tra cÃ¢u há»i liÃªn quan khoÃ¡ng sáº£n"""
    mineral_keywords = [
        'khoÃ¡ng sáº£n', 'khai thÃ¡c', 'thÄƒm dÃ²', 'Ä‘Ã¡', 'cÃ¡t', 'sá»i',
        'than', 'quáº·ng', 'kim loáº¡i', 'khoÃ¡ng', 'luáº­t khoÃ¡ng sáº£n',
        'giáº¥y phÃ©p', 'cáº¥p phÃ©p', 'thuáº¿ tÃ i nguyÃªn', 'phÃ­ thÄƒm dÃ²',
        'bá»™ tÃ i nguyÃªn', 'monre', 'tn&mt', 'má»', 'mining'
    ]
    return any(keyword in message.lower() for keyword in mineral_keywords)

def should_search_web(message):
    """Kiá»ƒm tra cáº§n tÃ¬m kiáº¿m web"""
    search_indicators = ['má»›i nháº¥t', 'cáº­p nháº­t', 'hiá»‡n hÃ nh', 'ban hÃ nh', 'nghá»‹ Ä‘á»‹nh', 'thÃ´ng tÆ°', 'luáº­t', 'phÃ¡p luáº­t', 'Ä‘iá»u']
    return is_mineral_related(message) and any(indicator in message.lower() for indicator in search_indicators)

def validate_law_number(law_number, law_year):
    """Kiá»ƒm tra tÃ­nh há»£p lá»‡ cá»§a sá»‘ hiá»‡u vÄƒn báº£n"""
    valid_laws = [
        {"number": "60/2010/QH12", "year": 2010, "title": "Luáº­t KhoÃ¡ng sáº£n"},
        {"number": "54/2024/QH15", "year": 2024, "title": "Luáº­t Äá»‹a cháº¥t vÃ  KhoÃ¡ng sáº£n"}
    ]
    for law in valid_laws:
        if law_number == law["number"] and law_year == law["year"]:
            return True
    return False

def simple_web_search(query, max_results=3):
    """TÃ¬m kiáº¿m web tá»‘i Æ°u, Æ°u tiÃªn vbpl.vn"""
    try:
        trusted_domains = ["vbpl.vn", "thuvienphapluat.vn", "monre.gov.vn", "chinhphu.vn"]
        encoded_query = quote(f"{query} khoÃ¡ng sáº£n site:vbpl.vn")
        search_url = "https://www.googleapis.com/customsearch/v1"
        params = {
            'key': st.secrets.get("GOOGLE_API_KEY"),
            'cx': st.secrets.get("GOOGLE_CSE_ID"),
            'q': encoded_query,
            'num': max_results,
            'siteSearch': "site:vbpl.vn"
        }
        response = requests.get(search_url, params=params, timeout=10)
        results = []
        if response.status_code == 200:
            data = response.json()
            for item in data.get('items', [])[:max_results]:
                content = item.get('snippet', '')
                if len(content) > 50 and "vbpl.vn" in item.get('link', ''):
                    # Kiá»ƒm tra sá»‘ hiá»‡u vÄƒn báº£n trong tiÃªu Ä‘á» hoáº·c ná»™i dung
                    law_match = re.search(r'(\d+/\d{4}/QH\d+)', content)
                    if law_match:
                        law_number = law_match.group(1)
                        year = int(law_number.split('/')[1])
                        if not validate_law_number(law_number, year):
                            continue  # Bá» qua náº¿u sá»‘ hiá»‡u khÃ´ng há»£p lá»‡
                    results.append({
                        'title': item.get('title', '')[:100],
                        'content': content[:500],
                        'url': item.get('link', ''),
                        'source': 'vbpl.vn'
                    })
            return results
        return []
    except Exception as e:
        return []

def create_search_prompt(user_message, search_results):
    """Táº¡o prompt vá»›i káº¿t quáº£ tÃ¬m kiáº¿m"""
    if not search_results:
        return f"{user_message}\n\nLÆ°u Ã½: KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin tá»« vbpl.vn. Vui lÃ²ng kiá»ƒm tra táº¡i vbpl.vn hoáº·c thuvienphapluat.vn."
    
    search_info = "\n\n=== THÃ”NG TIN TÃŒM KIáº¾M ===\n"
    for i, result in enumerate(search_results, 1):
        search_info += f"\nNguá»“n {i} ({result['source']}):\nTiÃªu Ä‘á»: {result['title']}\nNá»™i dung: {result['content']}...\nURL: {result['url']}\n---\n"
    search_info += """HÆ¯á»šNG DáºªN:
- Æ¯u tiÃªn thÃ´ng tin tá»« vbpl.vn, thuvienphapluat.vn, monre.gov.vn, chinhphu.vn.
- TrÃ­ch dáº«n vÄƒn báº£n, Ä‘iá»u, khoáº£n cá»¥ thá»ƒ náº¿u cÃ³.
- Khuyáº¿n nghá»‹ kiá»ƒm tra vbpl.vn Ä‘á»ƒ xÃ¡c nháº­n.\n=== Káº¾T THÃšC ===\n"""
    return search_info + f"CÃ¢u há»i: {user_message}"

def main():
    init_session_state()
    st.markdown("""
    <style>
    .assistant-message { background: #f0f8ff; padding: 15px; border-radius: 15px; margin: 10px 0; max-width: 80%; border-left: 4px solid #4CAF50; }
    .assistant-message::before { content: "âš–ï¸ Trá»£ lÃ½ PhÃ¡p cháº¿: "; font-weight: bold; color: #2E7D32; }
    .user-message { background: #e3f2fd; padding: 15px; border-radius: 15px; margin: 10px 0 10px auto; max-width: 80%; text-align: right; border-right: 4px solid #2196F3; }
    .user-message::before { content: "ğŸ‘¤ Báº¡n: "; font-weight: bold; color: #1976D2; }
    .stats-box { background: #f5f5f5; padding: 10px; border-radius: 8px; border: 1px solid #ddd; margin: 5px 0; }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div style="text-align: center; padding: 20px; background: linear-gradient(90deg, #2E7D32, #4CAF50); border-radius: 10px; margin-bottom: 20px;">
        <h1 style="color: white; margin: 0;">âš–ï¸ Trá»£ lÃ½ PhÃ¡p cháº¿ KhoÃ¡ng sáº£n</h1>
        <p style="color: #E8F5E8; margin: 5px 0 0 0;">ChuyÃªn gia tÆ° váº¥n Quáº£n lÃ½ NhÃ  nÆ°á»›c vá» KhoÃ¡ng sáº£n</p>
    </div>
    """, unsafe_allow_html=True)
    
    with st.sidebar:
        st.markdown("### âš™ï¸ CÃ i Ä‘áº·t")
        web_search_enabled = st.toggle("ğŸ” TÃ¬m kiáº¿m phÃ¡p luáº­t", value=True)
        model_options = ["gpt-4o-mini", "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview"]
        model_info = {
            "gpt-4o-mini": "ğŸ’° Ráº» nháº¥t",
            "gpt-3.5-turbo": "âš–ï¸ CÃ¢n báº±ng", 
            "gpt-4": "ğŸ§  ThÃ´ng minh",
            "gpt-4-turbo-preview": "ğŸš€ Nhanh"
        }
        default_model = get_default_model()
        default_index = model_options.index(default_model) if default_model in model_options else 0
        selected_model = st.selectbox("ğŸ¤– Model AI:", model_options, index=default_index)
        st.caption(model_info[selected_model])
        temperature = st.slider("ğŸŒ¡ï¸ Äá»™ sÃ¡ng táº¡o:", 0.0, 1.0, 0.3, 0.1)
        
        st.markdown("---")
        st.markdown("### ğŸ“Š Thá»‘ng kÃª")
        stats = safe_get_stats()
        st.markdown('<div class="stats-box">', unsafe_allow_html=True)
        st.metric("ğŸ¯ Tá»•ng Token", f"{stats['total_tokens']:,}")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“¥ Input", f"{stats['input_tokens']:,}")
        with col2:
            st.metric("ğŸ“¤ Output", f"{stats['output_tokens']:,}")
        st.markdown('</div>', unsafe_allow_html=True)
        st.markdown('<div class="stats-box">', unsafe_allow_html=True)
        st.metric("ğŸ’° Chi phÃ­ (USD)", f"${stats['total_cost_usd']:.4f}")
        st.metric("ğŸ’¸ Chi phÃ­ (VND)", f"{stats['total_cost_vnd']:,.0f}Ä‘")
        st.markdown('</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ Reset stats"):
                st.session_state.token_stats = {
                    "total_input_tokens": 0,
                    "total_output_tokens": 0,
                    "total_cost": 0.0,
                    "session_start": datetime.now(),
                    "request_count": 0
                }
                st.rerun()
        with col2:
            if st.button("ğŸ—‘ï¸ XÃ³a chat"):
                st.session_state.messages = [
                    {"role": "system", "content": get_system_prompt()},
                    {"role": "assistant", "content": get_welcome_message()}
                ]
                st.rerun()
        
        st.markdown("---")
        st.markdown("### ğŸ“š ChuyÃªn mÃ´n")
        st.markdown("â€¢ Luáº­t KhoÃ¡ng sáº£n\nâ€¢ Nghá»‹ Ä‘á»‹nh\nâ€¢ ThÃ´ng tÆ°\nâ€¢ Cáº¥p phÃ©p\nâ€¢ Thuáº¿, phÃ­\nâ€¢ Xá»­ pháº¡t")
        st.success("âœ… PhiÃªn báº£n á»•n Ä‘á»‹nh")

    if not st.secrets.get("OPENAI_API_KEY") or not st.secrets.get("GOOGLE_API_KEY") or not st.secrets.get("GOOGLE_CSE_ID"):
        st.error("âŒ ChÆ°a cáº¥u hÃ¬nh API keys!")
        st.stop()
    
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    
    for message in st.session_state.messages:
        if message["role"] == "assistant":
            st.markdown(f'<div class="assistant-message">{message["content"]}</div>', unsafe_allow_html=True)
        elif message["role"] == "user":
            st.markdown(f'<div class="user-message">{message["content"]}</div>', unsafe_allow_html=True)
    
    if prompt := st.chat_input("Nháº­p cÃ¢u há»i vá» khoÃ¡ng sáº£n..."):
        if not is_mineral_related(prompt):
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.markdown(f'<div class="user-message">{prompt}</div>', unsafe_allow_html=True)
            polite_refusal = """Xin lá»—i, tÃ´i chá»‰ tÆ° váº¥n vá» khoÃ¡ng sáº£n. Há»i vá» Luáº­t KhoÃ¡ng sáº£n, cáº¥p phÃ©p, thuáº¿ phÃ­, hoáº·c xá»­ pháº¡t nhÃ©! ğŸ˜Š"""
            st.session_state.messages.append({"role": "assistant", "content": polite_refusal})
            st.markdown(f'<div class="assistant-message">{polite_refusal}</div>', unsafe_allow_html=True)
            return
        
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.markdown(f'<div class="user-message">{prompt}</div>', unsafe_allow_html=True)
        
        with st.spinner("ğŸ¤” Äang xá»­ lÃ½..."):
            search_results = []
            final_prompt = prompt
            if web_search_enabled and should_search_web(prompt):
                with st.status("ğŸ” Äang tÃ¬m kiáº¿m..."):
                    search_results = simple_web_search(prompt)
                    if search_results:
                        st.success(f"âœ… TÃ¬m tháº¥y {len(search_results)} káº¿t quáº£ tá»« vbpl.vn")
                        for i, result in enumerate(search_results, 1):
                            st.write(f"**{i}. {result['source']}:** {result['title'][:50]}...")
                        final_prompt = create_search_prompt(prompt, search_results)
                    else:
                        st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ tá»« vbpl.vn")
            
            messages_for_api = [
                msg for msg in st.session_state.messages[:-1] 
                if msg["role"] != "system" or msg == st.session_state.messages[0]
            ]
            messages_for_api.append({"role": "user", "content": final_prompt})
            input_tokens = count_tokens("\n".join([msg["content"] for msg in messages_for_api]))
            
            try:
                response = ""
                stream = client.chat.completions.create(
                    model=selected_model,
                    messages=messages_for_api,
                    stream=True,
                    temperature=temperature,
                    max_tokens=2000
                )
                response_container = st.empty()
                for chunk in stream:
                    if chunk.choices and chunk.choices[0].delta.content:
                        response += chunk.choices[0].delta.content
                        response_container.markdown(f'<div class="assistant-message">{response}â–Œ</div>', unsafe_allow_html=True)
                
                response_container.markdown(f'<div class="assistant-message">{response}</div>', unsafe_allow_html=True)
                output_tokens = count_tokens(response)
                update_stats(input_tokens, output_tokens, selected_model)
                
                with st.expander("ğŸ“Š Thá»‘ng kÃª yÃªu cáº§u"):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Input tokens", f"{input_tokens:,}")
                    with col2:
                        st.metric("Output tokens", f"{output_tokens:,}")
                    with col3:
                        pricing = MODEL_PRICING[selected_model]
                        cost = (input_tokens / 1000) * pricing["input"] + (output_tokens / 1000) * pricing["output"]
                        st.metric("Chi phÃ­", f"${cost:.4f}")
                
            except Exception as e:
                response = f"âŒ Lá»—i: {str(e)}"
                st.markdown(f'<div class="assistant-message">{response}</div>', unsafe_allow_html=True)
        
        st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()