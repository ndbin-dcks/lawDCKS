import streamlit as st
from openai import OpenAI
import requests
import json
from datetime import datetime
import re
from urllib.parse import quote
import time
import os

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="AI Assistant v·ªõi Web Search",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# H√†m ƒë·ªçc n·ªôi dung t·ª´ file vƒÉn b·∫£n v·ªõi error handling
def rfile(name_file):
    try:
        with open(name_file, "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        # Fallback content n·∫øu file kh√¥ng t·ªìn t·∫°i
        fallback_content = {
            "00.xinchao.txt": "ü§ñ Tr·ª£ l√Ω AI th√¥ng minh",
            "01.system_trainning.txt": "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch, th√¥ng minh v√† th√¢n thi·ªán. H√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† h·ªØu √≠ch.",
            "02.assistant.txt": "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI c·ªßa b·∫°n. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m ki·∫øm th√¥ng tin, tr·∫£ l·ªùi c√¢u h·ªèi v√† h·ªó tr·ª£ nhi·ªÅu c√¥ng vi·ªác kh√°c. B·∫°n c·∫ßn t√¥i gi√∫p g√¨?",
            "module_chatgpt.txt": "gpt-3.5-turbo"
        }
        return fallback_content.get(name_file, f"N·ªôi dung m·∫∑c ƒë·ªãnh cho {name_file}")

# L·ªõp x·ª≠ l√Ω t√¨m ki·∫øm web t·ªëi ∆∞u cho Streamlit Cloud
class CloudWebSearcher:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
    def search(self, query, max_results=3):
        """T√¨m ki·∫øm web v·ªõi error handling m·∫°nh m·∫Ω"""
        try:
            # Th·ª≠ DuckDuckGo instant answer tr∆∞·ªõc
            results = self._search_duckduckgo_instant(query, max_results)
            
            if not results:
                # Fallback sang Wikipedia search
                results = self._search_wikipedia(query, max_results)
            
            return results[:max_results]
            
        except Exception as e:
            st.error(f"L·ªói t√¨m ki·∫øm: {str(e)}")
            return self._get_fallback_result(query)
    
    def _search_duckduckgo_instant(self, query, max_results):
        """T√¨m ki·∫øm v·ªõi DuckDuckGo instant answer"""
        try:
            params = {
                'q': query,
                'format': 'json',
                'no_html': '1',
                'skip_disambig': '1'
            }
            
            response = self.session.get(
                "https://api.duckduckgo.com/", 
                params=params, 
                timeout=10
            )
            
            if response.status_code != 200:
                return []
                
            data = response.json()
            results = []
            
            # Abstract answer
            if data.get('Abstract') and len(data['Abstract']) > 50:
                results.append({
                    'title': data.get('AbstractText', 'Th√¥ng tin t·ªïng quan')[:100],
                    'content': data.get('Abstract'),
                    'url': data.get('AbstractURL', ''),
                    'source': data.get('AbstractSource', 'DuckDuckGo')
                })
            
            # Related topics
            for topic in data.get('RelatedTopics', [])[:max_results-len(results)]:
                if isinstance(topic, dict) and topic.get('Text'):
                    results.append({
                        'title': topic.get('Text', '')[:80] + '...',
                        'content': topic.get('Text', ''),
                        'url': topic.get('FirstURL', ''),
                        'source': 'DuckDuckGo'
                    })
            
            return results
            
        except Exception as e:
            return []
    
    def _search_wikipedia(self, query, max_results):
        """T√¨m ki·∫øm Wikipedia ti·∫øng Vi·ªát"""
        try:
            # Wikipedia API search
            search_params = {
                'action': 'query',
                'list': 'search',
                'srsearch': query,
                'format': 'json',
                'srlimit': max_results
            }
            
            search_response = self.session.get(
                'https://vi.wikipedia.org/api/rest_v1/page/summary/' + quote(query),
                timeout=10
            )
            
            results = []
            
            if search_response.status_code == 200:
                data = search_response.json()
                if data.get('extract'):
                    results.append({
                        'title': data.get('title', 'Wikipedia'),
                        'content': data.get('extract', ''),
                        'url': data.get('content_urls', {}).get('desktop', {}).get('page', ''),
                        'source': 'Wikipedia'
                    })
            
            return results
            
        except Exception as e:
            return []
    
    def _get_fallback_result(self, query):
        """K·∫øt qu·∫£ d·ª± ph√≤ng khi t√¨m ki·∫øm th·∫•t b·∫°i"""
        return [{
            'title': 'Kh√¥ng th·ªÉ t√¨m ki·∫øm web',
            'content': f'Xin l·ªói, hi·ªán t·∫°i kh√¥ng th·ªÉ t√¨m ki·∫øm th√¥ng tin cho: "{query}". T√¥i s·∫Ω tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c c√≥ s·∫µn.',
            'url': '',
            'source': 'H·ªá th·ªëng'
        }]

# Kh·ªüi t·∫°o web searcher
@st.cache_resource
def get_web_searcher():
    return CloudWebSearcher()

web_searcher = get_web_searcher()

# H√†m ph√¢n t√≠ch xem c√≥ c·∫ßn t√¨m ki·∫øm web kh√¥ng
def should_search_web(message):
    """Ki·ªÉm tra xem c√¢u h·ªèi c√≥ c·∫ßn t√¨m ki·∫øm web kh√¥ng"""
    search_indicators = [
        # Ti·∫øng Vi·ªát
        't√¨m ki·∫øm', 'tin t·ª©c', 'th√¥ng tin m·ªõi', 'c·∫≠p nh·∫≠t', 'hi·ªán t·∫°i', 
        'g·∫ßn ƒë√¢y', 'm·ªõi nh·∫•t', 'th·ªùi ti·∫øt', 'gi√°', 't·ª∑ gi√°', 'h√¥m nay',
        'what is', 'who is', 'where is', 'when did', 'how much',
        # Ti·∫øng Anh
        'search', 'news', 'latest', 'current', 'recent', 'today',
        'weather', 'price', 'stock', 'rate'
    ]
    
    message_lower = message.lower()
    return any(indicator in message_lower for indicator in search_indicators)

# H√†m t·∫°o prompt v·ªõi k·∫øt qu·∫£ t√¨m ki·∫øm
def create_enhanced_prompt(user_message, search_results):
    """T·∫°o prompt k·∫øt h·ª£p th√¥ng tin t√¨m ki·∫øm"""
    if not search_results or not any(r.get('content') for r in search_results):
        return user_message
    
    search_info = "\n\n=== TH√îNG TIN T√åM KI·∫æM WEB ===\n"
    for i, result in enumerate(search_results, 1):
        if result.get('content'):
            search_info += f"\nNgu·ªìn {i} ({result['source']}):\n"
            search_info += f"Ti√™u ƒë·ªÅ: {result['title']}\n"
            search_info += f"N·ªôi dung: {result['content'][:500]}...\n"
            if result.get('url'):
                search_info += f"URL: {result['url']}\n"
            search_info += "---\n"
    
    search_info += "\nH∆∞·ªõng d·∫´n: S·ª≠ d·ª•ng th√¥ng tin tr√™n ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng. "
    search_info += "H√£y tr√≠ch d·∫´n ngu·ªìn r√µ r√†ng b·∫±ng c√°ch vi·∫øt 'Theo [T√™n ngu·ªìn]' ho·∫∑c 'D·ª±a theo [T√™n ngu·ªìn]'.\n"
    search_info += "=== K·∫æT TH√öC TH√îNG TIN T√åM KI·∫æM ===\n\n"
    
    return search_info + f"C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {user_message}"

# Main UI
def main():
    # Header
    st.markdown(
        """
        <div style="text-align: center; padding: 20px;">
            <h1 style="color: #1f77b4;">ü§ñ AI Assistant v·ªõi Web Search</h1>
            <p style="color: #666;">Tr·ª£ l√Ω AI th√¥ng minh v·ªõi kh·∫£ nƒÉng t√¨m ki·∫øm web v√† tr√≠ch d·∫´n ngu·ªìn</p>
        </div>
        """,
        unsafe_allow_html=True
    )
    
    # Sidebar
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è C√†i ƒë·∫∑t")
        
        # Toggle web search
        web_search_enabled = st.toggle("üîç T√¨m ki·∫øm web", value=True)
        
        # Model selection
        model_options = ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview"]
        selected_model = st.selectbox("ü§ñ Ch·ªçn model AI:", model_options, index=0)
        
        # Temperature setting
        temperature = st.slider("üå°Ô∏è Creativity (Temperature):", 0.0, 1.0, 0.7, 0.1)
        
        st.markdown("---")
        
        # Clear chat button
        if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
            st.session_state.messages = [
                {"role": "system", "content": rfile("01.system_trainning.txt")},
                {"role": "assistant", "content": rfile("02.assistant.txt")}
            ]
            st.rerun()
        
        st.markdown("---")
        st.markdown("### üí° M·∫πo s·ª≠ d·ª•ng")
        st.markdown("‚Ä¢ H·ªèi v·ªÅ tin t·ª©c, th·ªùi ti·∫øt, gi√° c·∫£ ƒë·ªÉ k√≠ch ho·∫°t t√¨m ki·∫øm web")
        st.markdown("‚Ä¢ Bot s·∫Ω t·ª± ƒë·ªông tr√≠ch d·∫´n ngu·ªìn khi t√¨m th·∫•y th√¥ng tin")
        st.markdown("‚Ä¢ C√≥ th·ªÉ t·∫Øt t√¨m ki·∫øm web n·∫øu ch·ªâ mu·ªën chat th√¥ng th∆∞·ªùng")
    
    # Check API key
    if not st.secrets.get("OPENAI_API_KEY"):
        st.error("‚ùå Ch∆∞a c·∫•u h√¨nh OPENAI_API_KEY trong secrets!")
        st.stop()
    
    # Initialize OpenAI client
    try:
        client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    except Exception as e:
        st.error(f"‚ùå L·ªói kh·ªüi t·∫°o OpenAI client: {str(e)}")
        st.stop()
    
    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": rfile("01.system_trainning.txt")},
            {"role": "assistant", "content": rfile("02.assistant.txt")}
        ]
    
    # Display chat history
    for message in st.session_state.messages:
        if message["role"] == "assistant":
            with st.chat_message("assistant", avatar="ü§ñ"):
                st.markdown(message["content"])
        elif message["role"] == "user":
            with st.chat_message("user", avatar="üë§"):
                st.markdown(message["content"])
    
    # Chat input
    if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n..."):
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user", avatar="üë§"):
            st.markdown(prompt)
        
        # Process response
        with st.chat_message("assistant", avatar="ü§ñ"):
            response_placeholder = st.empty()
            
            # Check if web search is needed
            search_results = []
            final_prompt = prompt
            
            if web_search_enabled and should_search_web(prompt):
                with st.status("üîç ƒêang t√¨m ki·∫øm th√¥ng tin tr√™n web...", expanded=False) as status:
                    search_results = web_searcher.search(prompt, max_results=3)
                    
                    if search_results and any(r.get('content') for r in search_results):
                        st.success(f"‚úÖ T√¨m th·∫•y {len(search_results)} k·∫øt qu·∫£")
                        for i, result in enumerate(search_results, 1):
                            if result.get('content'):
                                st.write(f"**{i}. {result['source']}:** {result['title'][:50]}...")
                        
                        final_prompt = create_enhanced_prompt(prompt, search_results)
                        status.update(label="‚úÖ Ho√†n t·∫•t t√¨m ki·∫øm", state="complete", expanded=False)
                    else:
                        status.update(label="‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£", state="complete", expanded=False)
            
            # Generate AI response
            try:
                messages_for_api = [
                    msg for msg in st.session_state.messages[:-1] 
                    if msg["role"] != "system" or msg == st.session_state.messages[0]
                ]
                messages_for_api.append({"role": "user", "content": final_prompt})
                
                response = ""
                stream = client.chat.completions.create(
                    model=selected_model,
                    messages=messages_for_api,
                    stream=True,
                    temperature=temperature,
                    max_tokens=2000
                )
                
                for chunk in stream:
                    if chunk.choices and chunk.choices[0].delta.content:
                        response += chunk.choices[0].delta.content
                        response_placeholder.markdown(response + "‚ñå")
                
                response_placeholder.markdown(response)
                
            except Exception as e:
                error_msg = f"‚ùå L·ªói: {str(e)}"
                response_placeholder.markdown(error_msg)
                response = error_msg
        
        # Add assistant response to history
        st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()