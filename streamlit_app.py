import streamlit as st
from openai import OpenAI
import requests
import json
from datetime import datetime
import re
from urllib.parse import quote
import time
import os

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="‚öñÔ∏è Tr·ª£ l√Ω Ph√°p ch·∫ø Kho√°ng s·∫£n Vi·ªát Nam",
    page_icon="‚öñÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Model pricing (USD per 1K tokens)
MODEL_PRICING = {
    "gpt-4o-mini": {"input": 0.00015, "output": 0.0006},
    "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002},
    "gpt-4": {"input": 0.03, "output": 0.06},
    "gpt-4-turbo-preview": {"input": 0.01, "output": 0.03}
}

def init_session_state():
    """Kh·ªüi t·∫°o session state an to√†n"""
    if "token_stats" not in st.session_state:
        st.session_state.token_stats = {
            "total_input_tokens": 0,
            "total_output_tokens": 0,
            "total_cost": 0.0,
            "session_start": datetime.now(),
            "request_count": 0
        }
    
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": get_system_prompt()},
            {"role": "assistant", "content": get_welcome_message()}
        ]

def safe_get_stats():
    """L·∫•y stats m·ªôt c√°ch an to√†n"""
    try:
        init_session_state()
        stats = st.session_state.token_stats
        total_tokens = stats["total_input_tokens"] + stats["total_output_tokens"]
        
        return {
            "total_tokens": total_tokens,
            "input_tokens": stats["total_input_tokens"],
            "output_tokens": stats["total_output_tokens"],
            "total_cost_usd": stats["total_cost"],
            "total_cost_vnd": stats["total_cost"] * 24000,
            "requests": stats["request_count"],
            "session_duration": datetime.now() - stats["session_start"]
        }
    except Exception as e:
        # Return default stats if error
        return {
            "total_tokens": 0,
            "input_tokens": 0,
            "output_tokens": 0,
            "total_cost_usd": 0.0,
            "total_cost_vnd": 0.0,
            "requests": 0,
            "session_duration": datetime.now() - datetime.now()
        }

def update_stats(input_tokens, output_tokens, model):
    """C·∫≠p nh·∫≠t stats an to√†n"""
    try:
        init_session_state()
        
        # Calculate cost
        if model not in MODEL_PRICING:
            model = "gpt-4o-mini"
        
        pricing = MODEL_PRICING[model]
        cost = (input_tokens / 1000) * pricing["input"] + (output_tokens / 1000) * pricing["output"]
        
        # Update stats
        st.session_state.token_stats["total_input_tokens"] += input_tokens
        st.session_state.token_stats["total_output_tokens"] += output_tokens
        st.session_state.token_stats["total_cost"] += cost
        st.session_state.token_stats["request_count"] += 1
        
    except Exception as e:
        st.error(f"L·ªói c·∫≠p nh·∫≠t stats: {e}")

def count_tokens(text):
    """∆Ø·ªõc t√≠nh s·ªë token ƒë∆°n gi·∫£n"""
    return len(str(text)) // 4

def get_system_prompt():
    """L·∫•y system prompt - KH√îNG c√≥ th√¥ng tin ph√°p lu·∫≠t c·ª• th·ªÉ"""
    try:
        with open("01.system_trainning.txt", "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        return """B·∫°n l√† chuy√™n gia ph√°p ch·∫ø v·ªÅ qu·∫£n l√Ω nh√† n∆∞·ªõc trong lƒ©nh v·ª±c kho√°ng s·∫£n t·∫°i Vi·ªát Nam.

‚öñÔ∏è NGUY√äN T·∫ÆC L√ÄM VI·ªÜC:
1. CH·ªà t·∫≠p trung v√†o c√°c v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn kho√°ng s·∫£n ·ªü Vi·ªát Nam
2. ƒê∆∞a ra th√¥ng tin ch√≠nh x√°c, d·∫´n chi·∫øu c·ª• th·ªÉ ƒëi·ªÅu kho·∫£n ph√°p lu·∫≠t khi c√≥
3. Gi·∫£i th√≠ch r√µ r√†ng, d·ªÖ hi·ªÉu cho c·∫£ chuy√™n gia v√† ng∆∞·ªùi d√¢n
4. Khi c√≥ th√¥ng tin web, ∆∞u ti√™n ngu·ªìn ch√≠nh th·ªëng: thuvienphapluat.vn, monre.gov.vn
5. T·ª´ ch·ªëi l·ªãch s·ª± c√°c c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn kho√°ng s·∫£n

üéØ C√ÅCH TR√çCH D·∫™N:
- Lu√¥n ghi r√µ t√™n vƒÉn b·∫£n ph√°p lu·∫≠t, ƒëi·ªÅu, kho·∫£n c·ª• th·ªÉ n·∫øu c√≥
- Khi c√≥ th√¥ng tin web: "D·ª±a theo th√¥ng tin t·ª´ [ngu·ªìn ch√≠nh th·ªëng]..."
- Khi kh√¥ng ch·∫Øc ch·∫Øn: "Th√¥ng tin tham kh·∫£o, vui l√≤ng ki·ªÉm tra t·∫°i thuvienphapluat.vn"

üìã C√ÅC CH·ª¶ ƒê·ªÄ CH√çNH:
1. Quy·ªÅn khai th√°c kho√°ng s·∫£n v√† th·ªß t·ª•c c·∫•p ph√©p
2. Nghƒ©a v·ª• c·ªßa t·ªï ch·ª©c, c√° nh√¢n khai th√°c kho√°ng s·∫£n  
3. Thu·∫ø t√†i nguy√™n v√† c√°c kho·∫£n thu kh√°c
4. B·∫£o v·ªá m√¥i tr∆∞·ªùng trong ho·∫°t ƒë·ªông kho√°ng s·∫£n
5. X·ª≠ ph·∫°t vi ph·∫°m h√†nh ch√≠nh
6. Thanh tra, ki·ªÉm tra ho·∫°t ƒë·ªông kho√°ng s·∫£n

QUAN TR·ªåNG: 
- Ch·ªâ tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ kho√°ng s·∫£n
- N·∫øu c√¢u h·ªèi kh√¥ng li√™n quan, h√£y l·ªãch s·ª± chuy·ªÉn h∆∞·ªõng v·ªÅ lƒ©nh v·ª±c chuy√™n m√¥n
- Lu√¥n khuy·∫øn ngh·ªã ki·ªÉm tra th√¥ng tin t·∫°i thuvienphapluat.vn ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh ch√≠nh x√°c"""

def get_welcome_message():
    """L·∫•y tin nh·∫Øn ch√†o m·ª´ng - KH√îNG c√≥ th√¥ng tin ph√°p lu·∫≠t c·ª• th·ªÉ"""
    try:
        with open("02.assistant.txt", "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        return """Xin ch√†o! ‚öñÔ∏è 

T√¥i l√† **Tr·ª£ l√Ω Ph√°p ch·∫ø chuy√™n v·ªÅ Qu·∫£n l√Ω Nh√† n∆∞·ªõc trong lƒ©nh v·ª±c Kho√°ng s·∫£n t·∫°i Vi·ªát Nam**.

üèîÔ∏è **T√¥i c√≥ th·ªÉ h·ªó tr·ª£ b·∫°n v·ªÅ:**

‚úÖ **Ph√°p lu·∫≠t Kho√°ng s·∫£n:**
   ‚Ä¢ Lu·∫≠t Kho√°ng s·∫£n v√† c√°c vƒÉn b·∫£n h∆∞·ªõng d·∫´n
   ‚Ä¢ Ngh·ªã ƒë·ªãnh, Th√¥ng t∆∞ c·ªßa B·ªô T√†i nguy√™n v√† M√¥i tr∆∞·ªùng

‚úÖ **Th·ªß t·ª•c h√†nh ch√≠nh:**
   ‚Ä¢ C·∫•p Gi·∫•y ph√©p thƒÉm d√≤, khai th√°c kho√°ng s·∫£n
   ‚Ä¢ Gia h·∫°n, s·ª≠a ƒë·ªïi, b·ªï sung gi·∫•y ph√©p
   ‚Ä¢ Th·ªß t·ª•c ƒë√≥ng c·ª≠a m·ªè

‚úÖ **Thu·∫ø v√† c√°c kho·∫£n thu:**
   ‚Ä¢ Thu·∫ø t√†i nguy√™n
   ‚Ä¢ Ti·ªÅn c·∫•p quy·ªÅn khai th√°c kho√°ng s·∫£n
   ‚Ä¢ Ph√≠ thƒÉm d√≤ kho√°ng s·∫£n

‚úÖ **X·ª≠ ph·∫°t vi ph·∫°m h√†nh ch√≠nh:**
   ‚Ä¢ C√°c h√†nh vi vi ph·∫°m v√† m·ª©c ph·∫°t
   ‚Ä¢ Bi·ªán ph√°p kh·∫Øc ph·ª•c h·∫≠u qu·∫£
   ‚Ä¢ Th·∫©m quy·ªÅn x·ª≠ ph·∫°t

‚úÖ **B·∫£o v·ªá m√¥i tr∆∞·ªùng:**
   ‚Ä¢ ƒê√°nh gi√° t√°c ƒë·ªông m√¥i tr∆∞·ªùng
   ‚Ä¢ K·∫ø ho·∫°ch b·∫£o v·ªá m√¥i tr∆∞·ªùng
   ‚Ä¢ Ph·ª•c h·ªìi m√¥i tr∆∞·ªùng sau khai th√°c

üéØ **L∆∞u √Ω quan tr·ªçng:** 
T√¥i ch·ªâ t∆∞ v·∫•n v·ªÅ lƒ©nh v·ª±c **Kho√°ng s·∫£n**. ƒê·ªëi v·ªõi c√°c v·∫•n ƒë·ªÅ kh√°c, b·∫°n vui l√≤ng tham kh·∫£o chuy√™n gia ph√π h·ª£p.

**B·∫°n c√≥ th·∫Øc m·∫Øc g√¨ v·ªÅ ph√°p lu·∫≠t Kho√°ng s·∫£n kh√¥ng?** ü§î

*V√≠ d·ª• c√¢u h·ªèi:*
- "Th·ªß t·ª•c xin ph√©p khai th√°c ƒë√° nh∆∞ th·∫ø n√†o?"
- "M·ª©c thu·∫ø t√†i nguy√™n hi·ªán t·∫°i?"
- "Vi ph·∫°m khai th√°c kho√°ng s·∫£n b·ªã ph·∫°t nh∆∞ th·∫ø n√†o?"
- "ƒêi·ªÅu ki·ªán c·∫•p Gi·∫•y ph√©p thƒÉm d√≤?"

‚ö†Ô∏è **L∆∞u √Ω quan tr·ªçng:** ƒê·ªÉ c√≥ th√¥ng tin ch√≠nh x√°c v√† c·∫≠p nh·∫≠t nh·∫•t, b·∫°n n√™n tham kh·∫£o tr·ª±c ti·∫øp t·∫°i **thuvienphapluat.vn** ho·∫∑c li√™n h·ªá c∆° quan c√≥ th·∫©m quy·ªÅn."""

def get_default_model():
    """L·∫•y model m·∫∑c ƒë·ªãnh"""
    try:
        with open("module_chatgpt.txt", "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "gpt-4o-mini"

def is_mineral_related(message):
    """Ki·ªÉm tra c√¢u h·ªèi c√≥ li√™n quan ƒë·∫øn kho√°ng s·∫£n kh√¥ng"""
    mineral_keywords = [
        'kho√°ng s·∫£n', 'khai th√°c', 'thƒÉm d√≤', 'ƒë√°', 'c√°t', 's·ªèi',
        'than', 'qu·∫∑ng', 'kim lo·∫°i', 'phi kim lo·∫°i', 'kho√°ng',
        'lu·∫≠t kho√°ng s·∫£n', 'gi·∫•y ph√©p', 'c·∫•p ph√©p', 'thu·∫ø t√†i nguy√™n',
        'ph√≠ thƒÉm d√≤', 'ti·ªÅn c·∫•p quy·ªÅn', 'vi ph·∫°m h√†nh ch√≠nh',
        'b·ªô t√†i nguy√™n', 's·ªü t√†i nguy√™n', 'monre', 'tn&mt',
        'm·ªè', 'm·ªè ƒë√°', 'm·ªè c√°t', 'm·ªè than', 'quarry', 'mining'
    ]
    
    message_lower = message.lower()
    return any(keyword in message_lower for keyword in mineral_keywords)

def should_search_web(message):
    """Ki·ªÉm tra c√≥ c·∫ßn t√¨m ki·∫øm web kh√¥ng"""
    search_indicators = [
        'm·ªõi nh·∫•t', 'c·∫≠p nh·∫≠t', 'hi·ªán h√†nh', 'ban h√†nh', 's·ª≠a ƒë·ªïi',
        'b·ªï sung', 'thay th·∫ø', 'c√≥ hi·ªáu l·ª±c', 'quy ƒë·ªãnh m·ªõi',
        'ngh·ªã ƒë·ªãnh', 'th√¥ng t∆∞', 'lu·∫≠t', 'ph√°p lu·∫≠t', 'ƒëi·ªÅu'
    ]
    
    message_lower = message.lower()
    return (is_mineral_related(message) and 
            any(indicator in message_lower for indicator in search_indicators))

def advanced_web_search(query, max_results=3):
    """T√¨m ki·∫øm web n√¢ng cao v·ªõi confidence scoring"""
    results = []
    
    try:
        # T√¨m ki·∫øm tr√™n thuvienphapluat.vn tr∆∞·ªõc
        params = {
            'q': f"site:thuvienphapluat.vn {query} kho√°ng s·∫£n",
            'format': 'json',
            'no_html': '1',
            'skip_disambig': '1'
        }
        
        response = requests.get("https://api.duckduckgo.com/", params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            # Abstract answer
            if data.get('Abstract') and len(data['Abstract']) > 50:
                confidence = calculate_confidence(query, data.get('AbstractText', ''), data.get('Abstract'))
                results.append({
                    'title': data.get('AbstractText', 'Th√¥ng tin ph√°p lu·∫≠t')[:100],
                    'content': data.get('Abstract'),
                    'url': data.get('AbstractURL', ''),
                    'source': 'Th∆∞ vi·ªán Ph√°p lu·∫≠t',
                    'priority': True,
                    'confidence': confidence
                })
            
            # Related topics
            for topic in data.get('RelatedTopics', [])[:max_results-len(results)]:
                if isinstance(topic, dict) and topic.get('Text'):
                    confidence = calculate_confidence(query, topic.get('Text', ''), topic.get('Text', ''))
                    results.append({
                        'title': topic.get('Text', '')[:80] + '...',
                        'content': topic.get('Text', ''),
                        'url': topic.get('FirstURL', ''),
                        'source': 'Th∆∞ vi·ªán Ph√°p lu·∫≠t',
                        'priority': True,
                        'confidence': confidence
                    })
        
        # N·∫øu kh√¥ng ƒë·ªß k·∫øt qu·∫£, t√¨m th√™m tr√™n c√°c domain ch√≠nh ph·ªß
        if len(results) < max_results:
            gov_domains = ['portal.gov.vn', 'monre.gov.vn', 'moj.gov.vn']
            for domain in gov_domains:
                if len(results) >= max_results:
                    break
                    
                try:
                    params = {
                        'q': f"site:{domain} {query}",
                        'format': 'json',
                        'no_html': '1'
                    }
                    
                    response = requests.get("https://api.duckduckgo.com/", params=params, timeout=8)
                    
                    if response.status_code == 200:
                        data = response.json()
                        
                        if data.get('Abstract'):
                            confidence = calculate_confidence(query, data.get('AbstractText', ''), data.get('Abstract'))
                            results.append({
                                'title': data.get('AbstractText', 'Th√¥ng tin ch√≠nh ph·ªß')[:100],
                                'content': data.get('Abstract'),
                                'url': data.get('AbstractURL', ''),
                                'source': f'C·ªïng {domain}',
                                'priority': True,
                                'confidence': confidence
                            })
                            
                except Exception:
                    continue
    
    except Exception as e:
        pass
    
    return results[:max_results]

def calculate_confidence(query, title, content):
    """T√≠nh ƒë·ªô tin c·∫≠y c·ªßa k·∫øt qu·∫£ t√¨m ki·∫øm"""
    confidence = 0.3  # Base confidence
    
    query_words = set(query.lower().split())
    content_words = set((title + ' ' + content).lower().split())
    
    # Word matching
    common_words = query_words.intersection(content_words)
    if len(query_words) > 0:
        word_match_ratio = len(common_words) / len(query_words)
        confidence += word_match_ratio * 0.4
    
    # Legal indicators
    if re.search(r'ƒëi·ªÅu\s+\d+', content.lower()):
        confidence += 0.2
    
    if re.search(r'kho·∫£n\s+\d+', content.lower()):
        confidence += 0.1
    
    if any(domain in content.lower() for domain in ['thuvienphapluat', 'gov.vn']):
        confidence += 0.2
    
    if re.search(r'lu·∫≠t\s+kho√°ng s·∫£n', content.lower()):
        confidence += 0.3
    
    return min(confidence, 1.0)

def create_enhanced_search_prompt(user_message, search_results):
    """T·∫°o prompt v·ªõi k·∫øt qu·∫£ t√¨m ki·∫øm ƒë∆∞·ª£c s·∫Øp x·∫øp theo ƒë·ªô tin c·∫≠y"""
    if not search_results:
        return f"""
{user_message}

QUAN TR·ªåNG: Kh√¥ng t√¨m th·∫•y th√¥ng tin ch√≠nh x√°c t·ª´ c√°c ngu·ªìn ph√°p lu·∫≠t ch√≠nh th·ªëng.
H√£y tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c c√≥ s·∫µn v√† L∆ØU √ù:
1. Ghi r√µ ƒë√¢y l√† th√¥ng tin tham kh·∫£o, ch∆∞a ƒë∆∞·ª£c x√°c minh t·ª´ ngu·ªìn ch√≠nh th·ªëng
2. Khuy·∫øn ngh·ªã ng∆∞·ªùi h·ªèi tham kh·∫£o tr·ª±c ti·∫øp t·∫°i thuvienphapluat.vn
3. N·∫øu l√† ƒëi·ªÅu kho·∫£n c·ª• th·ªÉ, ƒë·ªÅ xu·∫•t t√¨m ki·∫øm tr·ª±c ti·∫øp tr√™n website ch√≠nh th·ªëng
4. ƒê∆∞a ra link tr·ª±c ti·∫øp: https://thuvienphapluat.vn
"""
    
    # S·∫Øp x·∫øp k·∫øt qu·∫£ theo ƒë·ªô tin c·∫≠y v√† priority
    sorted_results = sorted(search_results, 
                          key=lambda x: (x.get('priority', False), x.get('confidence', 0)), 
                          reverse=True)
    
    search_info = "\n\n=== TH√îNG TIN PH√ÅP LU·∫¨T T√åM KI·∫æM ===\n"
    high_confidence_found = any(r.get('confidence', 0) > 0.7 for r in sorted_results)
    
    for i, result in enumerate(sorted_results, 1):
        priority_mark = "‚≠ê " if result.get('priority') else ""
        confidence = result.get('confidence', 0)
        confidence_mark = f"[Tin c·∫≠y: {confidence:.1f}]"
        
        search_info += f"\n{priority_mark}Ngu·ªìn {i} ({result['source']}) {confidence_mark}:\n"
        search_info += f"Ti√™u ƒë·ªÅ: {result['title']}\n"
        search_info += f"N·ªôi dung: {result['content'][:500]}...\n"
        
        if result.get('url'):
            search_info += f"URL: {result['url']}\n"
        search_info += "---\n"
    
    confidence_instruction = ""
    if high_confidence_found:
        confidence_instruction = "C√ì NGU·ªíN TIN C·∫¨Y CAO - H√£y ∆∞u ti√™n c√°c ngu·ªìn c√≥ ƒë·ªô tin c·∫≠y > 0.7"
    else:
        confidence_instruction = "KH√îNG C√ì NGU·ªíN TIN C·∫¨Y CAO - H√£y th·∫≠n tr·ªçng khi tr√≠ch d·∫´n v√† ghi r√µ c·∫ßn x√°c minh"
    
    search_info += f"""
{confidence_instruction}

H∆Ø·ªöNG D·∫™N TR√çCH D·∫™N CH√çNH X√ÅC:
1. ∆Øu ti√™n ngu·ªìn c√≥ ‚≠ê (ngu·ªìn ch√≠nh th·ªëng) 
2. ∆Øu ti√™n k·∫øt qu·∫£ c√≥ ƒë·ªô tin c·∫≠y cao (> 0.7)
3. PH·∫¢I tr√≠ch d·∫´n c·ª• th·ªÉ n·∫øu c√≥: "Theo ƒêi·ªÅu X kho·∫£n Y [T√™n lu·∫≠t/ngh·ªã ƒë·ªãnh]..."
4. N·∫øu ƒë·ªô tin c·∫≠y th·∫•p: "Th√¥ng tin tham kh·∫£o t·ª´ [ngu·ªìn], c·∫ßn x√°c minh th√™m"
5. Lu√¥n khuy·∫øn ngh·ªã: "ƒê·ªÉ c√≥ th√¥ng tin ch√≠nh x√°c nh·∫•t, vui l√≤ng tham kh·∫£o t·∫°i thuvienphapluat.vn"

=== K·∫æT TH√öC TH√îNG TIN PH√ÅP LU·∫¨T ===

"""
    
    return search_info + f"C√¢u h·ªèi: {user_message}"

def main():
    # Kh·ªüi t·∫°o session state
    init_session_state()
    
    # CSS
    st.markdown("""
    <style>
    .assistant-message {
        background: #f0f8ff;
        padding: 15px;
        border-radius: 15px;
        margin: 10px 0;
        max-width: 80%;
        border-left: 4px solid #4CAF50;
    }
    .assistant-message::before { 
        content: "‚öñÔ∏è Tr·ª£ l√Ω Ph√°p ch·∫ø: "; 
        font-weight: bold; 
        color: #2E7D32;
    }
    
    .user-message {
        background: #e3f2fd;
        padding: 15px;
        border-radius: 15px;
        margin: 10px 0 10px auto;
        max-width: 80%;
        text-align: right;
        border-right: 4px solid #2196F3;
    }
    .user-message::before { 
        content: "üë§ B·∫°n: "; 
        font-weight: bold; 
        color: #1976D2;
    }
    
    .stats-box {
        background: #f5f5f5;
        padding: 10px;
        border-radius: 8px;
        border: 1px solid #ddd;
        margin: 5px 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Header
    st.markdown("""
    <div style="text-align: center; padding: 20px; background: linear-gradient(90deg, #2E7D32, #4CAF50); border-radius: 10px; margin-bottom: 20px;">
        <h1 style="color: white; margin: 0;">‚öñÔ∏è Tr·ª£ l√Ω Ph√°p ch·∫ø Kho√°ng s·∫£n</h1>
        <p style="color: #E8F5E8; margin: 5px 0 0 0;">Chuy√™n gia t∆∞ v·∫•n Qu·∫£n l√Ω Nh√† n∆∞·ªõc v·ªÅ Kho√°ng s·∫£n t·∫°i Vi·ªát Nam</p>
        <p style="color: #E8F5E8; margin: 5px 0 0 0; font-size: 12px;">üÜï Phi√™n b·∫£n an to√†n ‚Ä¢ Real-time search ‚Ä¢ Confidence scoring</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è C√†i ƒë·∫∑t h·ªá th·ªëng")
        
        # Web search toggle
        web_search_enabled = st.toggle("üîç T√¨m ki·∫øm ph√°p lu·∫≠t online", value=True)
        
        # Model selection
        model_options = ["gpt-4o-mini", "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview"]
        model_info = {
            "gpt-4o-mini": "üí∞ R·∫ª nh·∫•t ($0.15/$0.6 per 1K tokens)",
            "gpt-3.5-turbo": "‚öñÔ∏è C√¢n b·∫±ng ($1.5/$2 per 1K tokens)", 
            "gpt-4": "üß† Th√¥ng minh ($30/$60 per 1K tokens)",
            "gpt-4-turbo-preview": "üöÄ Nhanh ($10/$30 per 1K tokens)"
        }
        
        default_model = get_default_model()
        default_index = model_options.index(default_model) if default_model in model_options else 0
        
        selected_model = st.selectbox("ü§ñ Ch·ªçn model AI:", model_options, index=default_index)
        st.caption(model_info[selected_model])
        
        # Temperature
        temperature = st.slider("üå°Ô∏è ƒê·ªô s√°ng t·∫°o:", 0.0, 1.0, 0.3, 0.1)
        
        st.markdown("---")
        
        # Stats
        st.markdown("### üìä Th·ªëng k√™ s·ª≠ d·ª•ng")
        
        try:
            stats = safe_get_stats()
            
            st.markdown('<div class="stats-box">', unsafe_allow_html=True)
            st.metric("üéØ T·ªïng Token", f"{stats['total_tokens']:,}")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("üì• Input", f"{stats['input_tokens']:,}")
            with col2:
                st.metric("üì§ Output", f"{stats['output_tokens']:,}")
            st.markdown('</div>', unsafe_allow_html=True)
            
            st.markdown('<div class="stats-box">', unsafe_allow_html=True)
            st.metric("üí∞ Chi ph√≠ (USD)", f"${stats['total_cost_usd']:.4f}")
            st.metric("üí∏ Chi ph√≠ (VND)", f"{stats['total_cost_vnd']:,.0f}ƒë")
            st.markdown('</div>', unsafe_allow_html=True)
            
            st.markdown('<div class="stats-box">', unsafe_allow_html=True)
            st.metric("üìû S·ªë l∆∞·ª£t h·ªèi", stats['requests'])
            duration = str(stats['session_duration']).split('.')[0]
            st.metric("‚è±Ô∏è Th·ªùi gian", duration)
            st.markdown('</div>', unsafe_allow_html=True)
            
        except Exception as e:
            st.error(f"L·ªói hi·ªÉn th·ªã stats: {e}")
        
        # Buttons
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üîÑ Reset stats", use_container_width=True):
                try:
                    st.session_state.token_stats = {
                        "total_input_tokens": 0,
                        "total_output_tokens": 0,
                        "total_cost": 0.0,
                        "session_start": datetime.now(),
                        "request_count": 0
                    }
                    st.rerun()
                except Exception as e:
                    st.error(f"L·ªói reset: {e}")
        
        with col2:
            if st.button("üóëÔ∏è X√≥a chat", use_container_width=True):
                try:
                    st.session_state.messages = [
                        {"role": "system", "content": get_system_prompt()},
                        {"role": "assistant", "content": get_welcome_message()}
                    ]
                    st.rerun()
                except Exception as e:
                    st.error(f"L·ªói x√≥a chat: {e}")
        
        st.markdown("---")
        st.markdown("### üìö Lƒ©nh v·ª±c chuy√™n m√¥n")
        st.markdown("‚Ä¢ Lu·∫≠t Kho√°ng s·∫£n v√† Lu·∫≠t ƒê·ªãa ch·∫•t Kho√°ng s·∫£n")
        st.markdown("‚Ä¢ Ngh·ªã ƒë·ªãnh h∆∞·ªõng d·∫´n thi h√†nh")
        st.markdown("‚Ä¢ Th√¥ng t∆∞ B·ªô TN&MT")
        st.markdown("‚Ä¢ Th·ªß t·ª•c c·∫•p ph√©p")
        st.markdown("‚Ä¢ Thu·∫ø, ph√≠ kho√°ng s·∫£n")
        st.markdown("‚Ä¢ X·ª≠ ph·∫°t vi ph·∫°m")
        st.markdown("‚Ä¢ B·∫£o v·ªá m√¥i tr∆∞·ªùng")
        
        st.markdown("---")
        st.markdown("### üõ°Ô∏è ƒê·∫£m b·∫£o ch√≠nh x√°c")
        st.success("‚úÖ Zero hard-coded legal info")
        st.success("‚úÖ Real-time search ch√≠nh th·ªëng")
        st.success("‚úÖ Confidence scoring")
        st.info("üí° T·∫•t c·∫£ th√¥ng tin ph√°p lu·∫≠t ƒë·ªÅu real-time")
    
    # Check API key
    if not st.secrets.get("OPENAI_API_KEY"):
        st.error("‚ùå Ch∆∞a c·∫•u h√¨nh OPENAI_API_KEY trong secrets!")
        st.stop()
    
    # Initialize OpenAI client
    try:
        client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    except Exception as e:
        st.error(f"‚ùå L·ªói kh·ªüi t·∫°o OpenAI client: {str(e)}")
        st.stop()
    
    # Display chat history
    for message in st.session_state.messages:
        if message["role"] == "assistant":
            st.markdown(f'<div class="assistant-message">{message["content"]}</div>', 
                       unsafe_allow_html=True)
        elif message["role"] == "user":
            st.markdown(f'<div class="user-message">{message["content"]}</div>', 
                       unsafe_allow_html=True)
    
    # Chat input
    if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi v·ªÅ ph√°p lu·∫≠t kho√°ng s·∫£n..."):
        
        # Check if mineral related
        if not is_mineral_related(prompt):
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.markdown(f'<div class="user-message">{prompt}</div>', unsafe_allow_html=True)
            
            polite_refusal = """Xin l·ªói, t√¥i l√† tr·ª£ l√Ω chuy√™n v·ªÅ **ph√°p lu·∫≠t kho√°ng s·∫£n** t·∫°i Vi·ªát Nam.

T√¥i ch·ªâ c√≥ th·ªÉ t∆∞ v·∫•n v·ªÅ c√°c v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn:
- üèîÔ∏è Lu·∫≠t Kho√°ng s·∫£n v√† c√°c vƒÉn b·∫£n h∆∞·ªõng d·∫´n
- ‚öñÔ∏è Th·ªß t·ª•c c·∫•p ph√©p thƒÉm d√≤, khai th√°c kho√°ng s·∫£n
- üí∞ Thu·∫ø, ph√≠ li√™n quan ƒë·∫øn kho√°ng s·∫£n
- üå± B·∫£o v·ªá m√¥i tr∆∞·ªùng trong ho·∫°t ƒë·ªông kho√°ng s·∫£n
- ‚ö†Ô∏è X·ª≠ ph·∫°t vi ph·∫°m h√†nh ch√≠nh

B·∫°n c√≥ th·ªÉ h·ªèi t√¥i v·ªÅ nh·ªØng v·∫•n ƒë·ªÅ n√†y kh√¥ng? V√≠ d·ª•:
- "Th·ªß t·ª•c xin ph√©p khai th√°c ƒë√° nh∆∞ th·∫ø n√†o?"
- "M·ª©c thu·∫ø t√†i nguy√™n hi·ªán t·∫°i ra sao?"
- "Vi ph·∫°m trong khai th√°c kho√°ng s·∫£n b·ªã ph·∫°t nh∆∞ th·∫ø n√†o?"

T√¥i s·∫µn s√†ng h·ªó tr·ª£ b·∫°n! üòä"""
            
            st.session_state.messages.append({"role": "assistant", "content": polite_refusal})
            st.markdown(f'<div class="assistant-message">{polite_refusal}</div>', 
                       unsafe_allow_html=True)
            return
        
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.markdown(f'<div class="user-message">{prompt}</div>', unsafe_allow_html=True)
        
        # Process response
        with st.spinner("ü§î ƒêang ph√¢n t√≠ch c√¢u h·ªèi ph√°p lu·∫≠t..."):
            search_results = []
            final_prompt = prompt
            
            # Web search if enabled
            if web_search_enabled and should_search_web(prompt):
                with st.status("üîç ƒêang t√¨m ki·∫øm vƒÉn b·∫£n ph√°p lu·∫≠t ch√≠nh x√°c...", expanded=False) as status:
                    search_results = advanced_web_search(prompt)
                    
                    if search_results:
                        # ƒê·∫øm ngu·ªìn ∆∞u ti√™n v√† ƒë·ªô tin c·∫≠y cao
                        priority_count = sum(1 for r in search_results if r.get('priority'))
                        high_confidence_count = sum(1 for r in search_results if r.get('confidence', 0) > 0.7)
                        
                        if high_confidence_count > 0:
                            st.success(f"‚úÖ T√¨m th·∫•y {len(search_results)} k·∫øt qu·∫£ ({priority_count} ngu·ªìn ∆∞u ti√™n, {high_confidence_count} tin c·∫≠y cao)")
                        else:
                            st.warning(f"‚ö†Ô∏è T√¨m th·∫•y {len(search_results)} k·∫øt qu·∫£ ({priority_count} ngu·ªìn ∆∞u ti√™n) - ƒê·ªô tin c·∫≠y ch∆∞a cao")
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ªõi confidence scores
                        for i, result in enumerate(search_results, 1):
                            priority_mark = "‚≠ê " if result.get('priority') else ""
                            confidence = result.get('confidence', 0)
                            confidence_color = "üü¢" if confidence > 0.7 else "üü°" if confidence > 0.4 else "üî¥"
                            
                            st.write(f"**{priority_mark}{i}. {result['source']}** {confidence_color} [{confidence:.2f}]: {result['title'][:50]}...")
                        
                        final_prompt = create_enhanced_search_prompt(prompt, search_results)
                        status.update(label="‚úÖ Ho√†n t·∫•t t√¨m ki·∫øm ph√°p lu·∫≠t ch√≠nh x√°c", state="complete", expanded=False)
                    else:
                        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y vƒÉn b·∫£n ph√°p lu·∫≠t li√™n quan - S·∫Ω tr·∫£ l·ªùi t·ª´ ki·∫øn th·ª©c c√≥ s·∫µn")
                        status.update(label="‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y vƒÉn b·∫£n li√™n quan", state="complete", expanded=False)
            
            # Count input tokens
            messages_for_api = [
                msg for msg in st.session_state.messages[:-1] 
                if msg["role"] != "system" or msg == st.session_state.messages[0]
            ]
            messages_for_api.append({"role": "user", "content": final_prompt})
            
            input_text = "\n".join([msg["content"] for msg in messages_for_api])
            input_tokens = count_tokens(input_text)
            
            # Generate response
            try:
                response = ""
                
                stream = client.chat.completions.create(
                    model=selected_model,
                    messages=messages_for_api,
                    stream=True,
                    temperature=temperature,
                    max_tokens=2000
                )
                
                response_container = st.empty()
                
                for chunk in stream:
                    if chunk.choices and chunk.choices[0].delta.content:
                        response += chunk.choices[0].delta.content
                        response_container.markdown(
                            f'<div class="assistant-message">{response}‚ñå</div>', 
                            unsafe_allow_html=True
                        )
                
                # Final response
                response_container.markdown(
                    f'<div class="assistant-message">{response}</div>', 
                    unsafe_allow_html=True
                )
                
                # Update stats
                output_tokens = count_tokens(response)
                update_stats(input_tokens, output_tokens, selected_model)
                
                # Show request stats
                with st.expander("üìä Th·ªëng k√™ request n√†y"):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Input tokens", f"{input_tokens:,}")
                    with col2:
                        st.metric("Output tokens", f"{output_tokens:,}")
                    with col3:
                        if selected_model in MODEL_PRICING:
                            pricing = MODEL_PRICING[selected_model]
                            cost = (input_tokens / 1000) * pricing["input"] + (output_tokens / 1000) * pricing["output"]
                            st.metric("Chi ph√≠", f"${cost:.4f}")
                
            except Exception as e:
                error_msg = f"‚ùå L·ªói h·ªá th·ªëng: {str(e)}"
                st.markdown(f'<div class="assistant-message">{error_msg}</div>', 
                           unsafe_allow_html=True)
                response = error_msg
        
        # Add response to history
        st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()