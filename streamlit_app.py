import streamlit as st
from openai import OpenAI
import sqlite3
import json
from datetime import datetime
import re
import time
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

# Cáº¥u hÃ¬nh trang
st.set_page_config(
    page_title="âš–ï¸ Trá»£ lÃ½ PhÃ¡p cháº¿ KhoÃ¡ng sáº£n Viá»‡t Nam",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =================== CONFIGURATIONS ===================

MODEL_PRICING = {
    "gpt-4o-mini": {"input": 0.00015, "output": 0.0006},
    "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002},
    "gpt-4": {"input": 0.03, "output": 0.06},
    "gpt-4-turbo-preview": {"input": 0.01, "output": 0.03}
}

@dataclass
class VBPLConfig:
    """Cáº¥u hÃ¬nh cho VBPL integration"""
    vbpl_db_path: str = "vbpl.db"
    model: str = "gpt-4o-mini"
    max_tokens: int = 1500
    temperature: float = 0.1
    max_search_results: int = 5
    domain_focus: str = "khoÃ¡ng sáº£n"
    prioritize_active_docs: bool = True

# =================== VBPL DATABASE INTEGRATION ===================
# Thay tháº¿ TOÃ€N Bá»˜ class VBPLDatabase trong streamlit_app.py

class VBPLDatabase:
    """Database manager cho VBPL vá»›i DYNAMIC schema detection"""
    
    def __init__(self, config: VBPLConfig):
        self.config = config
        self.conn = None
        self.available = False
        self.content_table = None
        self.content_columns = []
        self.text_columns = []
        self._init_connection()
    
    def _init_connection(self):
        """Initialize database connection"""
        try:
            if not os.path.exists(self.config.vbpl_db_path):
                st.sidebar.warning(f"âš ï¸ Database file khÃ´ng tá»“n táº¡i: {self.config.vbpl_db_path}")
                return False
            
            self.conn = sqlite3.connect(self.config.vbpl_db_path, check_same_thread=False)
            self.conn.row_factory = sqlite3.Row
            self.available = True
            
            # Analyze database structure
            self._analyze_database()
            return True
            
        except Exception as e:
            st.sidebar.error(f"âŒ Lá»—i káº¿t ná»‘i database: {e}")
            return False
    
    def _analyze_database(self):
        """PhÃ¢n tÃ­ch cáº¥u trÃºc database vÃ  hiá»ƒn thá»‹ ACTUAL schema"""
        try:
            cursor = self.conn.cursor()
            
            # Get all tables
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            st.sidebar.success(f"âœ… VBPL Database Connected")
            st.sidebar.caption(f"ğŸ“Š Found {len(tables)} tables")
            
            # Show actual table structure
            with st.sidebar.expander("ğŸ” Database Schema Inspector", expanded=True):
                st.write("**ğŸ“‹ Available Tables:**")
                for table in tables:
                    st.write(f"â€¢ {table}")
                
                # Show detailed schema for key tables
                for table in tables[:5]:  # Limit to first 5 tables
                    try:
                        cursor.execute(f"PRAGMA table_info({table})")
                        columns = cursor.fetchall()
                        
                        st.write(f"\n**ğŸ“„ {table} structure:**")
                        for col in columns[:10]:  # Show first 10 columns
                            st.caption(f"  - {col[1]} ({col[2]})")
                        
                        # Show sample data count
                        cursor.execute(f"SELECT COUNT(*) FROM {table}")
                        count = cursor.fetchone()[0]
                        st.caption(f"  ğŸ“Š Rows: {count:,}")
                        
                        if count > 0 and count < 1000000:  # Safety check
                            cursor.execute(f"SELECT * FROM {table} LIMIT 1")
                            sample = cursor.fetchone()
                            if sample:
                                st.caption(f"  ğŸ“ Sample keys: {list(sample.keys())[:5]}")
                    
                    except Exception as e:
                        st.caption(f"  âŒ Error inspecting {table}: {e}")
            
            # Try to identify the correct content table
            self.content_table = self._identify_content_table(tables)
            if self.content_table:
                st.sidebar.info(f"ğŸ¯ Using content table: {self.content_table}")
                
                # Show identified text columns
                if self.text_columns:
                    st.sidebar.caption(f"ğŸ“ Text columns: {', '.join(self.text_columns[:3])}")
            else:
                st.sidebar.error("âŒ No suitable content table found")
            
        except Exception as e:
            st.sidebar.error(f"âŒ Database analysis failed: {e}")
    
    def _identify_content_table(self, tables: List[str]) -> Optional[str]:
        """Identify the correct table for legal content"""
        try:
            cursor = self.conn.cursor()
            
            # Possible table names for legal content (in priority order)
            candidate_tables = [
                'vbpl_content', 'legal_content', 'content', 'elements', 
                'vbpl_section', 'vbpl_clause', 'vbpl_point',
                'sections', 'clauses', 'points', 'articles',
                'documents'  # Fallback to documents table
            ]
            
            for candidate in candidate_tables:
                if candidate in tables:
                    try:
                        # Check table structure
                        cursor.execute(f"PRAGMA table_info({candidate})")
                        columns = [col[1] for col in cursor.fetchall()]
                        
                        # Look for text content columns
                        text_columns = [col for col in columns if any(
                            term in col.lower() for term in [
                                'content', 'text', 'body', 'description', 'name', 
                                'title', 'heading', 'summary', 'abstract'
                            ]
                        )]
                        
                        if text_columns:
                            # Check if it has substantial data
                            cursor.execute(f"SELECT COUNT(*) FROM {candidate}")
                            count = cursor.fetchone()[0]
                            
                            if count > 0:
                                # Check if text columns have actual content
                                sample_query = f"SELECT {text_columns[0]} FROM {candidate} WHERE {text_columns[0]} IS NOT NULL AND LENGTH(TRIM({text_columns[0]})) > 50 LIMIT 1"
                                cursor.execute(sample_query)
                                sample = cursor.fetchone()
                                
                                if sample and sample[0]:
                                    self.content_columns = columns
                                    self.text_columns = text_columns
                                    
                                    st.sidebar.success(f"âœ… Found content in table: {candidate}")
                                    st.sidebar.caption(f"ğŸ“Š {count:,} rows, {len(text_columns)} text columns")
                                    
                                    return candidate
                    
                    except Exception as e:
                        st.sidebar.warning(f"âš ï¸ Error checking {candidate}: {e}")
                        continue
            
            # If no direct match found, try to find any table with substantial text
            st.sidebar.warning("ğŸ” No standard content table found, searching all tables...")
            
            for table in tables:
                try:
                    cursor.execute(f"PRAGMA table_info({table})")
                    columns = [col[1] for col in cursor.fetchall()]
                    
                    # Look for any text columns
                    text_columns = [col for col in columns if any(
                        term in col.lower() for term in [
                            'content', 'text', 'body', 'name', 'title', 'description'
                        ]
                    )]
                    
                    if len(text_columns) >= 1:  # Need at least 1 text column
                        cursor.execute(f"SELECT COUNT(*) FROM {table}")
                        count = cursor.fetchone()[0]
                        
                        if count > 10:  # Some substantial data
                            # Test if has meaningful content
                            test_query = f"SELECT {text_columns[0]} FROM {table} WHERE {text_columns[0]} IS NOT NULL LIMIT 1"
                            cursor.execute(test_query)
                            sample = cursor.fetchone()
                            
                            if sample and len(str(sample[0])) > 20:
                                self.content_columns = columns
                                self.text_columns = text_columns
                                
                                st.sidebar.info(f"ğŸ” Using fallback table: {table}")
                                st.sidebar.caption(f"ğŸ“Š {count:,} rows, {len(text_columns)} text columns")
                                
                                return table
                
                except Exception:
                    continue
            
            return None
            
        except Exception as e:
            st.sidebar.error(f"âŒ Error identifying content table: {e}")
            return None
    
    def is_available(self) -> bool:
        """Check if database is available and has content table"""
        return self.available and self.conn is not None and self.content_table is not None
    
    def search_domain_specific(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """Search database vá»›i DYNAMIC schema detection"""
        if not self.is_available():
            st.error("âŒ Database hoáº·c content table khÃ´ng kháº£ dá»¥ng")
            return []
        
        try:
            cursor = self.conn.cursor()
            keywords = self._extract_smart_keywords(query)
            
            if not keywords:
                st.warning("âš ï¸ KhÃ´ng thá»ƒ trÃ­ch xuáº¥t tá»« khÃ³a tá»« cÃ¢u há»i")
                return []
            
            # Display search info
            st.write(f"ğŸ” **Table**: {self.content_table}")
            st.write(f"ğŸ” **Keywords**: {', '.join(keywords[:3])}")
            st.write(f"ğŸ“Š **Text columns**: {', '.join(self.text_columns[:3])}")
            
            # Build DYNAMIC search query based on actual schema
            search_conditions = []
            params = []
            
            # 1. Domain filtering cho khoÃ¡ng sáº£n
            domain_keywords = ['khoÃ¡ng sáº£n', 'tÃ i nguyÃªn', 'thÄƒm dÃ²', 'khai thÃ¡c', 'má»', 'Ä‘á»‹a cháº¥t']
            
            domain_conditions = []
            for text_col in self.text_columns[:3]:  # Limit to first 3 text columns
                for keyword in domain_keywords:
                    domain_conditions.append(f"LOWER({text_col}) LIKE ?")
                    params.append(f"%{keyword}%")
            
            if domain_conditions:
                search_conditions.append(f"({' OR '.join(domain_conditions)})")
            
            # 2. Query-specific keywords
            query_conditions = []
            for text_col in self.text_columns[:3]:  # Limit to first 3 text columns
                for keyword in keywords[:5]:  # Limit keywords
                    query_conditions.append(f"LOWER({text_col}) LIKE ?")
                    params.append(f"%{keyword}%")
            
            if query_conditions:
                search_conditions.append(f"({' OR '.join(query_conditions)})")
            
            # 3. Build SELECT with available columns
            column_mapping = self._build_column_mapping()
            
            # Select relevant columns that exist
            select_columns = []
            for standard_field, mapped_column in column_mapping.items():
                if mapped_column:
                    select_columns.append(mapped_column)
            
            # Ensure we have at least some columns
            if not select_columns:
                select_columns = self.content_columns[:10]  # First 10 columns as fallback
            
            # Remove duplicates while preserving order
            select_columns = list(dict.fromkeys(select_columns))
            
            # 4. Build final query
            sql = f"SELECT {', '.join(select_columns)} FROM {self.content_table}"
            
            if search_conditions:
                sql += f" WHERE {' AND '.join(search_conditions)}"
            
            # Add basic filtering if we have a main text column
            main_text_col = self.text_columns[0] if self.text_columns else None
            if main_text_col:
                if search_conditions:
                    sql += f" AND {main_text_col} IS NOT NULL"
                    sql += f" AND LENGTH(TRIM({main_text_col})) > 30"
                else:
                    sql += f" WHERE {main_text_col} IS NOT NULL"
                    sql += f" AND LENGTH(TRIM({main_text_col})) > 30"
                
                # Order by content length
                sql += f" ORDER BY LENGTH({main_text_col}) DESC"
            
            sql += f" LIMIT ?"
            params.append(max_results)
            
            st.write(f"ğŸ” **Query preview**: {sql[:150]}...")
            st.write(f"ğŸ“Š **Parameters**: {len(params)} params")
            
            cursor.execute(sql, params)
            results = cursor.fetchall()
            
            st.write(f"ğŸ“Š **Raw database results**: {len(results)}")
            
            # Process results vá»›i dynamic mapping
            processed_results = []
            for row in results:
                row_dict = dict(row)
                
                # Map to standard format
                mapped_result = {
                    'element_id': self._safe_get_field(row_dict, column_mapping, 'id'),
                    'element_type': self._safe_get_field(row_dict, column_mapping, 'type') or 'content',
                    'element_number': self._safe_get_field(row_dict, column_mapping, 'number'),
                    'element_name': self._safe_get_field(row_dict, column_mapping, 'name'),
                    'element_content': self._safe_get_field(row_dict, column_mapping, 'content'),
                    'document_number': self._safe_get_field(row_dict, column_mapping, 'document'),
                    'document_name': self._safe_get_field(row_dict, column_mapping, 'doc_name'),
                    'document_state': self._safe_get_field(row_dict, column_mapping, 'state') or 'Unknown',
                    'is_active': self._is_document_active(self._safe_get_field(row_dict, column_mapping, 'state')),
                    'relevance_score': self._calculate_relevance_dynamic(query, row_dict, column_mapping),
                    'raw_data': row_dict  # Keep original for debugging
                }
                
                # Only add if has some content
                if mapped_result['element_content'] and len(mapped_result['element_content'].strip()) > 20:
                    processed_results.append(mapped_result)
            
            # Sort by relevance and active status
            processed_results.sort(
                key=lambda x: (x['is_active'], x['relevance_score']), 
                reverse=True
            )
            
            st.success(f"âœ… Processed {len(processed_results)} valid results")
            
            return processed_results
            
        except Exception as e:
            st.error(f"âŒ Database search failed: {e}")
            import traceback
            st.code(traceback.format_exc())
            return []
    
    def _build_column_mapping(self) -> Dict[str, Optional[str]]:
        """Build mapping tá»« standard fields to actual columns"""
        column_mapping = {}
        
        # Field mapping definitions
        field_mappings = {
            'id': ['id', 'element_id', 'row_id', 'rowid', '_id'],
            'type': ['type', 'element_type', 'category', 'kind'],
            'number': ['number', 'element_number', 'section_number', 'article_number', 'clause_number'],
            'name': ['name', 'element_name', 'title', 'heading', 'subject'],
            'content': ['content', 'element_content', 'text', 'body', 'description', 'full_text'],
            'document': ['document', 'document_number', 'doc_number', 'source', 'doc_id'],
            'doc_name': ['document_name', 'doc_name', 'source_name', 'title'],
            'state': ['state', 'status', 'document_state', 'active', 'valid']
        }
        
        for standard_field, possible_columns in field_mappings.items():
            found_column = None
            for col in possible_columns:
                if col in self.content_columns:
                    found_column = col
                    break
            
            # Fallback: use first text column for content/name fields
            if not found_column and standard_field in ['content', 'name']:
                if self.text_columns:
                    found_column = self.text_columns[0]
            
            column_mapping[standard_field] = found_column
        
        return column_mapping
    
    def _safe_get_field(self, row_dict: Dict, column_mapping: Dict, field: str) -> str:
        """Safely get field value tá»« row"""
        column = column_mapping.get(field)
        if column and column in row_dict:
            value = row_dict[column]
            return str(value) if value is not None else ''
        return ''
    
    def _extract_smart_keywords(self, query: str) -> List[str]:
        """Extract smart keywords tá»« query vá»›i Vietnamese support"""
        # Vietnamese stop words
        stop_words = {
            'lÃ ', 'cá»§a', 'vÃ ', 'cÃ³', 'Ä‘Æ°á»£c', 'theo', 'trong', 'vá»', 'khi', 'nÃ o', 'gÃ¬', 'nhÆ°', 'tháº¿',
            'vá»›i', 'Ä‘á»ƒ', 'cho', 'tá»«', 'táº¡i', 'trÃªn', 'dÆ°á»›i', 'nÃ y', 'Ä‘Ã³', 'nhá»¯ng', 'cÃ¡c', 'má»™t',
            'hai', 'ba', 'bá»‘n', 'nÄƒm', 'sÃ¡u', 'báº£y', 'tÃ¡m', 'chÃ­n', 'mÆ°á»i', 'bá»‹', 'sáº½', 'Ä‘Ã£'
        }
        
        # Normalize vÃ  tokenize
        query_normalized = re.sub(r'[^\w\s]', ' ', query.lower())
        words = [w.strip() for w in query_normalized.split() if w.strip()]
        
        # Filter keywords
        keywords = [w for w in words if len(w) > 2 and w not in stop_words]
        
        # Add important bigrams for better matching
        bigrams = []
        for i in range(len(words) - 1):
            if (words[i] not in stop_words and words[i+1] not in stop_words 
                and len(words[i]) > 2 and len(words[i+1]) > 2):
                bigrams.append(f"{words[i]} {words[i+1]}")
        
        # Combine vÃ  limit Ä‘á»ƒ avoid quÃ¡ complex queries
        all_keywords = keywords[:4] + bigrams[:2]
        
        return all_keywords
    
    def _calculate_relevance_dynamic(self, query: str, row_dict: Dict, column_mapping: Dict) -> float:
        """Calculate relevance vá»›i dynamic column mapping"""
        score = 0.0
        query_lower = query.lower()
        
        # Score based on available mapped columns
        field_weights = {
            'content': 0.4,
            'name': 0.25,
            'doc_name': 0.15,
            'number': 0.1,
            'document': 0.1
        }
        
        for field, weight in field_weights.items():
            text = self._safe_get_field(row_dict, column_mapping, field)
            if text:
                text_lower = text.lower()
                
                # Exact match
                if query_lower in text_lower:
                    score += weight
                
                # Word overlap
                query_words = set(query_lower.split())
                text_words = set(text_lower.split())
                overlap = len(query_words.intersection(text_words))
                if len(query_words) > 0:
                    overlap_ratio = overlap / len(query_words)
                    score += (overlap_ratio * weight * 0.5)
        
        # Active document bonus
        state = self._safe_get_field(row_dict, column_mapping, 'state')
        if self._is_document_active(state):
            score += 0.15
        
        # Content length bonus
        content = self._safe_get_field(row_dict, column_mapping, 'content')
        if content:
            content_length = len(content)
            if content_length > 500:
                score += 0.05
            elif content_length > 200:
                score += 0.02
        
        return min(score, 1.0)
    
    def _is_document_active(self, state: str) -> bool:
        """Check if document is currently active"""
        if not state:
            return False
        
        state_lower = state.lower()
        active_indicators = ['cÃ²n hiá»‡u lá»±c', 'cÃ³ hiá»‡u lá»±c', 'hiá»‡n hÃ nh', 'active', 'valid', 'current']
        inactive_indicators = ['háº¿t hiá»‡u lá»±c', 'khÃ´ng hiá»‡u lá»±c', 'inactive', 'expired', 'invalid']
        
        # Check for active indicators
        if any(indicator in state_lower for indicator in active_indicators):
            return True
        
        # Check for inactive indicators
        if any(indicator in state_lower for indicator in inactive_indicators):
            return False
        
        # Default: assume active if state is not clearly inactive
        return True
    
    def close(self):
        """Close database connection"""
        if self.conn:
            self.conn.close()
            self.available = False
            self.content_table = None

class VBPLOpenAIProcessor:
    """OpenAI processor cho VBPL content vá»›i professional prompting"""
    
    def __init__(self, openai_client: OpenAI, config: VBPLConfig, db_manager: VBPLDatabase):
        self.client = openai_client
        self.config = config
        self.db_manager = db_manager
    
    def process_legal_query(self, query: str) -> Dict[str, Any]:
        """Process legal query vá»›i VBPL database"""
        
        # Step 1: Search database
        with st.status("ğŸ” Äang tÃ¬m kiáº¿m trong cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¡p luáº­t VBPL...", expanded=True) as status:
            
            search_results = self.db_manager.search_domain_specific(query, self.config.max_search_results)
            
            if search_results:
                active_count = sum(1 for r in search_results if r['is_active'])
                inactive_count = len(search_results) - active_count
                
                st.success(f"âœ… TÃ¬m tháº¥y {len(search_results)} káº¿t quáº£ chÃ­nh xÃ¡c")
                st.info(f"ğŸ“Š {active_count} vÄƒn báº£n cÃ²n hiá»‡u lá»±c, {inactive_count} vÄƒn báº£n háº¿t hiá»‡u lá»±c")
                
                # Display preview of results
                for i, result in enumerate(search_results, 1):
                    status_icon = "âœ…" if result['is_active'] else "âš ï¸"
                    st.write(f"**{i}. {status_icon} {result['element_number']}**")
                    if result['element_name']:
                        st.write(f"   ğŸ“‹ {result['element_name'][:80]}...")
                    st.write(f"   ğŸ“„ {result['document_number']} ({result['document_state']})")
                    st.write(f"   ğŸ¯ Score: {result['relevance_score']:.2f}")
                
                status.update(label="âœ… TÃ¬m kiáº¿m VBPL hoÃ n táº¥t", state="complete")
            else:
                st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ phÃ¹ há»£p trong database VBPL")
                status.update(label="âš ï¸ KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£", state="complete")
        
        # Step 2: Generate response
        if search_results:
            return self._generate_response_with_sources(query, search_results)
        else:
            return self._generate_fallback_response(query)
    
    def _generate_response_with_sources(self, query: str, search_results: List[Dict]) -> Dict[str, Any]:
        """Generate response vá»›i database sources"""
        
        # Create context tá»« search results
        context = self._create_structured_context(search_results)
        
        # Show context preview
        with st.expander("ğŸ“„ Context Ä‘Æ°á»£c gá»­i Ä‘áº¿n AI (Click Ä‘á»ƒ xem)", expanded=False):
            st.code(context[:1500] + "..." if len(context) > 1500 else context)
        
        # Call OpenAI
        try:
            response = self._call_openai_with_vbpl_context(query, context, search_results)
            
            return {
                'response': response,
                'sources': search_results,
                'active_sources': sum(1 for r in search_results if r['is_active']),
                'inactive_sources': sum(1 for r in search_results if not r['is_active']),
                'total_sources': len(search_results),
                'method': 'vbpl_database',
                'success': True
            }
            
        except Exception as e:
            st.error(f"âŒ Lá»—i OpenAI API: {e}")
            return {
                'response': f"TÃ´i Ä‘Ã£ tÃ¬m tháº¥y {len(search_results)} quy Ä‘á»‹nh liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u, nhÆ°ng gáº·p lá»—i khi xá»­ lÃ½ thÃ´ng tin. Vui lÃ²ng tham kháº£o trá»±c tiáº¿p cÃ¡c quy Ä‘á»‹nh sau hoáº·c liÃªn há»‡ cÆ¡ quan cÃ³ tháº©m quyá»n.",
                'sources': search_results,
                'method': 'vbpl_database_error',
                'success': False
            }
    
    def _generate_fallback_response(self, query: str) -> Dict[str, Any]:
        """Generate fallback response khi khÃ´ng cÃ³ database results"""
        
        fallback_response = """TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin cá»¥ thá»ƒ vá» váº¥n Ä‘á» nÃ y trong cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¡p luáº­t hiá»‡n cÃ³. 

ğŸ” **Äá»ƒ cÃ³ thÃ´ng tin chÃ­nh xÃ¡c nháº¥t, báº¡n vui lÃ²ng:**

1. **Tham kháº£o trá»±c tiáº¿p** táº¡i thuvienphapluat.vn
2. **LiÃªn há»‡** Sá»Ÿ TÃ i nguyÃªn vÃ  MÃ´i trÆ°á»ng Ä‘á»‹a phÆ°Æ¡ng  
3. **Tham kháº£o** Luáº­t KhoÃ¡ng sáº£n hiá»‡n hÃ nh vÃ  cÃ¡c nghá»‹ Ä‘á»‹nh hÆ°á»›ng dáº«n
4. **LiÃªn há»‡** hotline tÆ° váº¥n phÃ¡p luáº­t cá»§a Bá»™ TÆ° phÃ¡p

ğŸ’¡ **Gá»£i Ã½**: Thá»­ diá»…n Ä‘áº¡t cÃ¢u há»i khÃ¡c hoáº·c sá»­ dá»¥ng tá»« khÃ³a cá»¥ thá»ƒ hÆ¡n vá» lÄ©nh vá»±c khoÃ¡ng sáº£n."""

        return {
            'response': fallback_response,
            'sources': [],
            'method': 'vbpl_database_empty',
            'success': False
        }
    
    def _create_structured_context(self, results: List[Dict]) -> str:
        """Create structured context tá»« VBPL database results"""
        
        context = "=== THÃ”NG TIN Tá»ª CÆ  Sá» Dá»® LIá»†U PHÃP LUáº¬T VBPL ===\n\n"
        
        # Group by document status
        active_results = [r for r in results if r['is_active']]
        inactive_results = [r for r in results if not r['is_active']]
        
        if active_results:
            context += "ğŸ“‹ **QUY Äá»ŠNH CÃ’N HIá»†U Lá»°C (Æ¯u tiÃªn sá»­ dá»¥ng):**\n\n"
            for i, result in enumerate(active_results, 1):
                context += self._format_result_for_context(result, i, "âœ…")
        
        if inactive_results:
            context += "\nğŸ“‹ **QUY Äá»ŠNH Háº¾T HIá»†U Lá»°C (Chá»‰ tham kháº£o):**\n\n"
            for i, result in enumerate(inactive_results, 1):
                context += self._format_result_for_context(result, i, "âš ï¸")
        
        return context
    
    def _format_result_for_context(self, result: Dict, index: int, status_icon: str) -> str:
        """Format single result cho context"""
        
        entry = f"Nguá»“n {index} {status_icon}:\n"
        entry += f"â€¢ **VÄƒn báº£n**: {result['document_number']} - {result['document_name']}\n"
        entry += f"â€¢ **Tráº¡ng thÃ¡i**: {result['document_state']}\n"
        entry += f"â€¢ **Äiá»u khoáº£n**: {result['element_number']}"
        
        if result['element_name']:
            entry += f" - {result['element_name']}\n"
        else:
            entry += "\n"
        
        # Clean vÃ  format content
        content = result['element_content'].strip()
        if len(content) > 800:
            content = content[:800] + "..."
        
        entry += f"â€¢ **Ná»™i dung**: {content}\n"
        entry += f"â€¢ **Äá»™ liÃªn quan**: {result['relevance_score']:.2f}\n"
        entry += "---\n\n"
        
        return entry
    
    def _call_openai_with_vbpl_context(self, query: str, context: str, sources: List[Dict]) -> str:
        """Call OpenAI vá»›i VBPL context vÃ  professional prompting"""
        
        # Count sources
        active_sources = sum(1 for s in sources if s['is_active'])
        inactive_sources = len(sources) - active_sources
        
        # Professional system prompt cho khoÃ¡ng sáº£n
        system_prompt = """Báº¡n lÃ  chuyÃªn gia phÃ¡p luáº­t KHOÃNG Sáº¢N Viá»‡t Nam vá»›i chuyÃªn mÃ´n sÃ¢u vá» quy Ä‘á»‹nh phÃ¡p luáº­t.

ğŸ¯ **NHIá»†M Vá»¤ CHÃNH**:
- Tráº£ lá»i Dá»°A TRÃŠN quy Ä‘á»‹nh phÃ¡p luáº­t khoÃ¡ng sáº£n tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u VBPL
- Æ¯u tiÃªn tuyá»‡t Ä‘á»‘i QUY Äá»ŠNH CÃ’N HIá»†U Lá»°C (âœ…) hÆ¡n quy Ä‘á»‹nh háº¿t hiá»‡u lá»±c (âš ï¸)
- TrÃ­ch dáº«n CHÃNH XÃC Ä‘iá»u, khoáº£n, Ä‘iá»ƒm tá»« vÄƒn báº£n phÃ¡p luáº­t
- Giáº£i thÃ­ch THá»°C TIá»„N vÃ  dá»… hiá»ƒu cho doanh nghiá»‡p/cÃ¡ nhÃ¢n

ğŸš« **NGHIÃŠM Cáº¤M**:
- Suy luáº­n hoáº·c diá»…n giáº£i khi khÃ´ng cÃ³ thÃ´ng tin trá»±c tiáº¿p
- Sá»­ dá»¥ng quy Ä‘á»‹nh Háº¾T HIá»†U Lá»°C khi Ä‘Ã£ cÃ³ quy Ä‘á»‹nh CÃ’N HIá»†U Lá»°C
- TrÃ­ch dáº«n Ä‘iá»u luáº­t khÃ´ng trá»±c tiáº¿p liÃªn quan Ä‘áº¿n cÃ¢u há»i
- Bá»‹a Ä‘áº·t thÃ´ng tin khÃ´ng cÃ³ trong cÆ¡ sá»Ÿ dá»¯ liá»‡u

ğŸ“‹ **FORMAT CHUáº¨N**:
**ğŸ” Tráº£ lá»i**: [CÃ¢u tráº£ lá»i trá»±c tiáº¿p vÃ  rÃµ rÃ ng]

**âš–ï¸ CÄƒn cá»© phÃ¡p lÃ½**: 
[TrÃ­ch dáº«n cá»¥ thá»ƒ vá»›i tráº¡ng thÃ¡i hiá»‡u lá»±c]

**ğŸ’¡ LÆ°u Ã½ thá»±c tiá»…n**: [Náº¿u cáº§n thiáº¿t]

**ğŸ“Œ Khuyáº¿n nghá»‹**: [HÆ°á»›ng dáº«n thá»±c hiá»‡n hoáº·c tham kháº£o thÃªm]

ğŸ¯ **DOMAIN**: CHá»ˆ vá» KHOÃNG Sáº¢N - khÃ´ng Ã¡p dá»¥ng cho lÄ©nh vá»±c khÃ¡c."""

        user_prompt = f"""â“ **CÃ¢u há»i**: {query}

ğŸ“Š **Nguá»“n tá»« Database VBPL**: {active_sources} quy Ä‘á»‹nh cÃ²n hiá»‡u lá»±c + {inactive_sources} quy Ä‘á»‹nh háº¿t hiá»‡u lá»±c

{context}

ğŸ¯ **YÃªu cáº§u**: Tráº£ lá»i dá»±a trÃªn cÆ¡ sá»Ÿ dá»¯ liá»‡u VBPL trÃªn, TUYá»†T Äá»I Æ°u tiÃªn quy Ä‘á»‹nh CÃ’N HIá»†U Lá»°C."""

        try:
            response = self.client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=self.config.max_tokens,
                temperature=self.config.temperature
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            raise Exception(f"OpenAI API call failed: {e}")

# =================== STREAMLIT CORE FUNCTIONS ===================

def init_session_state():
    """Khá»Ÿi táº¡o session state"""
    if "token_stats" not in st.session_state:
        st.session_state.token_stats = {
            "total_input_tokens": 0,
            "total_output_tokens": 0,
            "total_cost": 0.0,
            "session_start": datetime.now(),
            "request_count": 0
        }
    
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": get_system_prompt()},
            {"role": "assistant", "content": get_welcome_message()}
        ]

def get_system_prompt():
    """Get system prompt tá»« file hoáº·c default"""
    try:
        with open("01.system_trainning.txt", "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        return """Báº¡n lÃ  chuyÃªn gia phÃ¡p cháº¿ vá» quáº£n lÃ½ nhÃ  nÆ°á»›c trong lÄ©nh vá»±c khoÃ¡ng sáº£n táº¡i Viá»‡t Nam, Ä‘Æ°á»£c há»— trá»£ bá»Ÿi cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¡p luáº­t VBPL chuyÃªn nghiá»‡p."""

def get_welcome_message():
    """Get welcome message"""
    try:
        with open("02.assistant.txt", "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        return """Xin chÃ o! âš–ï¸ 

TÃ´i lÃ  **Trá»£ lÃ½ PhÃ¡p cháº¿ chuyÃªn vá» KhoÃ¡ng sáº£n** Ä‘Æ°á»£c há»— trá»£ bá»Ÿi **cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¡p luáº­t VBPL**.

ğŸ—„ï¸ **TÃ´i cÃ³ thá»ƒ tÃ¬m kiáº¿m chÃ­nh xÃ¡c trong há»‡ thá»‘ng phÃ¡p luáº­t vá»:**
- Luáº­t KhoÃ¡ng sáº£n vÃ  cÃ¡c vÄƒn báº£n hÆ°á»›ng dáº«n
- Thá»§ tá»¥c cáº¥p phÃ©p thÄƒm dÃ², khai thÃ¡c
- Thuáº¿, phÃ­ liÃªn quan Ä‘áº¿n khoÃ¡ng sáº£n  
- Xá»­ pháº¡t vi pháº¡m hÃ nh chÃ­nh
- Báº£o vá»‡ mÃ´i trÆ°á»ng trong hoáº¡t Ä‘á»™ng khoÃ¡ng sáº£n

ğŸ’¡ **HÃ£y Ä‘áº·t cÃ¢u há»i cá»¥ thá»ƒ Ä‘á»ƒ tÃ´i tÃ¬m kiáº¿m chÃ­nh xÃ¡c trong database!**"""

def get_default_model():
    """Get default model"""
    try:
        with open("module_chatgpt.txt", "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "gpt-4o-mini"

def is_mineral_related(message):
    """Check if message is mineral-related"""
    mineral_keywords = [
        'khoÃ¡ng sáº£n', 'khai thÃ¡c', 'thÄƒm dÃ²', 'Ä‘Ã¡', 'cÃ¡t', 'sá»i',
        'than', 'quáº·ng', 'kim loáº¡i', 'phi kim loáº¡i', 'khoÃ¡ng',
        'luáº­t khoÃ¡ng sáº£n', 'giáº¥y phÃ©p', 'cáº¥p phÃ©p', 'thuáº¿ tÃ i nguyÃªn',
        'phÃ­ thÄƒm dÃ²', 'tiá»n cáº¥p quyá»n', 'vi pháº¡m hÃ nh chÃ­nh',
        'bá»™ tÃ i nguyÃªn', 'sá»Ÿ tÃ i nguyÃªn', 'monre', 'tn&mt',
        'má»', 'má» Ä‘Ã¡', 'má» cÃ¡t', 'má» than', 'quarry', 'mining',
        'thu há»“i giáº¥y phÃ©p', 'gia háº¡n', 'Ä‘Ã³ng cá»­a má»'
    ]
    
    message_lower = message.lower()
    return any(keyword in message_lower for keyword in mineral_keywords)

def count_tokens(text):
    """Estimate token count"""
    return len(str(text)) // 4

def update_stats(input_tokens, output_tokens, model):
    """Update token statistics"""
    try:
        if model not in MODEL_PRICING:
            model = "gpt-4o-mini"
        
        pricing = MODEL_PRICING[model]
        cost = (input_tokens / 1000) * pricing["input"] + (output_tokens / 1000) * pricing["output"]
        
        st.session_state.token_stats["total_input_tokens"] += input_tokens
        st.session_state.token_stats["total_output_tokens"] += output_tokens
        st.session_state.token_stats["total_cost"] += cost
        st.session_state.token_stats["request_count"] += 1
        
    except Exception as e:
        st.error(f"Error updating stats: {e}")

# =================== VBPL SYSTEM INITIALIZATION ===================

def init_vbpl_system():
    """Initialize VBPL system"""
    if 'vbpl_system' not in st.session_state:
        config = VBPLConfig()
        db_manager = VBPLDatabase(config)
        
        if db_manager.is_available():
            try:
                client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
                openai_processor = VBPLOpenAIProcessor(client, config, db_manager)
                
                st.session_state.vbpl_system = {
                    'config': config,
                    'db_manager': db_manager,
                    'openai_processor': openai_processor,
                    'available': True
                }
                
            except Exception as e:
                st.sidebar.error(f"âŒ VBPL system initialization failed: {e}")
                st.session_state.vbpl_system = {'available': False}
        else:
            st.session_state.vbpl_system = {'available': False}

def is_vbpl_available() -> bool:
    """Check if VBPL system is available"""
    return st.session_state.get('vbpl_system', {}).get('available', False)

def process_with_vbpl(query: str) -> Dict[str, Any]:
    """Process query vá»›i VBPL system"""
    if not is_vbpl_available():
        return {'method': 'vbpl_unavailable', 'success': False}
    
    processor = st.session_state.vbpl_system['openai_processor']
    return processor.process_legal_query(query)

def show_vbpl_results_details(result: Dict[str, Any]):
    """Show detailed VBPL results"""
    if not result.get('sources'):
        return
    
    st.markdown("### ğŸ“Š **Chi tiáº¿t káº¿t quáº£ tá»« Database VBPL**")
    
    # Summary metrics
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Tá»•ng káº¿t quáº£", result['total_sources'])
    with col2:
        st.metric("CÃ²n hiá»‡u lá»±c", result['active_sources'])
    with col3:
        st.metric("Háº¿t hiá»‡u lá»±c", result['inactive_sources'])
    
    # Detailed results
    for i, source in enumerate(result['sources'], 1):
        with st.expander(
            f"{i}. {'âœ…' if source['is_active'] else 'âš ï¸'} {source['element_number']}: {source['element_name'][:60]}...", 
            expanded=False
        ):
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.write(f"**ğŸ“„ VÄƒn báº£n**: {source['document_number']}")
                st.write(f"**ğŸ“‹ TÃªn vÄƒn báº£n**: {source['document_name']}")
                st.write(f"**âš–ï¸ Tráº¡ng thÃ¡i**: {source['document_state']}")
                st.write(f"**ğŸ“ Äiá»u khoáº£n**: {source['element_number']}")
                if source['element_name']:
                    st.write(f"**ğŸ·ï¸ TÃªn Ä‘iá»u khoáº£n**: {source['element_name']}")
            
            with col2:
                st.metric("Relevance Score", f"{source['relevance_score']:.2f}")
                st.metric("Element Type", source['element_type'])
                st.metric("Priority", "High" if source['is_active'] else "Low")
            
            st.markdown("**ğŸ“ Ná»™i dung Ä‘áº§y Ä‘á»§:**")
            st.write(source['element_content'])

# =================== MAIN APPLICATION ===================

def main():
    # Initialize systems
    init_session_state()
    init_vbpl_system()
    
    # CSS
    st.markdown("""
    <style>
    .assistant-message {
        background: #f0f8ff;
        padding: 15px;
        border-radius: 15px;
        margin: 10px 0;
        max-width: 80%;
        border-left: 4px solid #4CAF50;
    }
    .assistant-message::before { 
        content: "âš–ï¸ Trá»£ lÃ½ PhÃ¡p cháº¿: "; 
        font-weight: bold; 
        color: #2E7D32;
    }
    
    .user-message {
        background: #e3f2fd;
        padding: 15px;
        border-radius: 15px;
        margin: 10px 0 10px auto;
        max-width: 80%;
        text-align: right;
        border-right: 4px solid #2196F3;
    }
    .user-message::before { 
        content: "ğŸ‘¤ Báº¡n: "; 
        font-weight: bold; 
        color: #1976D2;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Header
    st.markdown("""
    <div style="text-align: center; padding: 20px; background: linear-gradient(90deg, #2E7D32, #4CAF50); border-radius: 10px; margin-bottom: 20px;">
        <h1 style="color: white; margin: 0;">âš–ï¸ Trá»£ lÃ½ PhÃ¡p cháº¿ KhoÃ¡ng sáº£n</h1>
        <p style="color: #E8F5E8; margin: 5px 0 0 0;">Há»— trá»£ bá»Ÿi CÆ¡ sá»Ÿ dá»¯ liá»‡u PhÃ¡p luáº­t VBPL</p>
        <p style="color: #E8F5E8; margin: 5px 0 0 0; font-size: 12px;">ğŸ—„ï¸ Database-Powered â€¢ Accurate Legal Content â€¢ Real-time Search</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.markdown("### âš™ï¸ CÃ i Ä‘áº·t há»‡ thá»‘ng")
        
        # VBPL status
        if is_vbpl_available():
            vbpl_enabled = st.toggle("ğŸ—„ï¸ Sá»­ dá»¥ng VBPL Database", value=True)
            st.success("âœ… VBPL Database Online")
        else:
            vbpl_enabled = False
            st.toggle("ğŸ—„ï¸ Sá»­ dá»¥ng VBPL Database", value=False, disabled=True)
            st.error("âŒ VBPL Database Offline")
            st.info("ğŸ’¡ Cáº§n file vbpl.db Ä‘á»ƒ sá»­ dá»¥ng")
        
        # Model selection
        model_options = ["gpt-4o-mini", "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview"]
        model_info = {
            "gpt-4o-mini": "ğŸ’° Ráº» nháº¥t ($0.15/$0.6 per 1K tokens)",
            "gpt-3.5-turbo": "âš–ï¸ CÃ¢n báº±ng ($1.5/$2 per 1K tokens)", 
            "gpt-4": "ğŸ§  ThÃ´ng minh ($30/$60 per 1K tokens)",
            "gpt-4-turbo-preview": "ğŸš€ Nhanh ($10/$30 per 1K tokens)"
        }
        
        default_model = get_default_model()
        default_index = model_options.index(default_model) if default_model in model_options else 0
        
        selected_model = st.selectbox("ğŸ¤– Chá»n model AI:", model_options, index=default_index)
        st.caption(model_info[selected_model])
        
        # Temperature
        temperature = st.slider("ğŸŒ¡ï¸ Äá»™ sÃ¡ng táº¡o:", 0.0, 1.0, 0.1, 0.1)
        
        st.markdown("---")
        
        # Statistics
        st.markdown("### ğŸ“Š Thá»‘ng kÃª sá»­ dá»¥ng")
        try:
            stats = st.session_state.token_stats
            total_tokens = stats["total_input_tokens"] + stats["total_output_tokens"]
            
            st.metric("ğŸ¯ Tá»•ng Token", f"{total_tokens:,}")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ğŸ“¥ Input", f"{stats['total_input_tokens']:,}")
            with col2:
                st.metric("ğŸ“¤ Output", f"{stats['total_output_tokens']:,}")
            
            st.metric("ğŸ’° Chi phÃ­ (USD)", f"${stats['total_cost']:.4f}")
            st.metric("ğŸ’¸ Chi phÃ­ (VND)", f"{stats['total_cost'] * 24000:,.0f}Ä‘")
            st.metric("ğŸ“ Sá»‘ lÆ°á»£t há»i", stats['request_count'])
            
        except Exception as e:
            st.error(f"Error displaying stats: {e}")
        
        # Reset buttons
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ Reset stats", use_container_width=True):
                st.session_state.token_stats = {
                    "total_input_tokens": 0,
                    "total_output_tokens": 0,
                    "total_cost": 0.0,
                    "session_start": datetime.now(),
                    "request_count": 0
                }
                st.rerun()
        
        with col2:
            if st.button("ğŸ—‘ï¸ XÃ³a chat", use_container_width=True):
                st.session_state.messages = [
                    {"role": "system", "content": get_system_prompt()},
                    {"role": "assistant", "content": get_welcome_message()}
                ]
                st.rerun()
        
        st.markdown("---")
        st.markdown("### ğŸ—„ï¸ VBPL Features")
        if is_vbpl_available():
            st.success("âœ… Structured legal database")
            st.success("âœ… Domain-specific filtering")
            st.success("âœ… Document status prioritization")
            st.success("âœ… Professional AI prompting")
            st.info("ğŸ’¡ TÃ¬m kiáº¿m chÃ­nh xÃ¡c trong database phÃ¡p luáº­t")
        else:
            st.info("ğŸ’¡ VBPL database cung cáº¥p:")
            st.write("â€¢ TÃ¬m kiáº¿m structured content")
            st.write("â€¢ Æ¯u tiÃªn vÄƒn báº£n cÃ²n hiá»‡u lá»±c")
            st.write("â€¢ TrÃ­ch dáº«n chÃ­nh xÃ¡c Ä‘iá»u khoáº£n")
            st.write("â€¢ Filtering domain khoÃ¡ng sáº£n")
    
    # Check OpenAI API
    if not st.secrets.get("OPENAI_API_KEY"):
        st.error("âŒ ChÆ°a cáº¥u hÃ¬nh OPENAI_API_KEY trong secrets!")
        st.stop()
    
    # Initialize OpenAI client
    try:
        client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    except Exception as e:
        st.error(f"âŒ Lá»—i khá»Ÿi táº¡o OpenAI client: {str(e)}")
        st.stop()
    
    # Display chat history
    for message in st.session_state.messages:
        if message["role"] == "assistant":
            st.markdown(f'<div class="assistant-message">{message["content"]}</div>', 
                       unsafe_allow_html=True)
        elif message["role"] == "user":
            st.markdown(f'<div class="user-message">{message["content"]}</div>', 
                       unsafe_allow_html=True)
    
    # Chat input
    if prompt := st.chat_input("Nháº­p cÃ¢u há»i vá» phÃ¡p luáº­t khoÃ¡ng sáº£n..."):
        
        # Check if mineral related
        if not is_mineral_related(prompt):
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.markdown(f'<div class="user-message">{prompt}</div>', unsafe_allow_html=True)
            
            polite_refusal = """Xin lá»—i, tÃ´i lÃ  trá»£ lÃ½ chuyÃªn vá» **phÃ¡p luáº­t khoÃ¡ng sáº£n** táº¡i Viá»‡t Nam.

TÃ´i chá»‰ cÃ³ thá»ƒ tÆ° váº¥n vá» cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n:
- ğŸ”ï¸ Luáº­t KhoÃ¡ng sáº£n vÃ  cÃ¡c vÄƒn báº£n hÆ°á»›ng dáº«n
- âš–ï¸ Thá»§ tá»¥c cáº¥p phÃ©p thÄƒm dÃ², khai thÃ¡c khoÃ¡ng sáº£n
- ğŸ’° Thuáº¿, phÃ­ liÃªn quan Ä‘áº¿n khoÃ¡ng sáº£n
- ğŸŒ± Báº£o vá»‡ mÃ´i trÆ°á»ng trong hoáº¡t Ä‘á»™ng khoÃ¡ng sáº£n
- âš ï¸ Xá»­ pháº¡t vi pháº¡m hÃ nh chÃ­nh

HÃ£y Ä‘áº·t cÃ¢u há»i vá» lÄ©nh vá»±c khoÃ¡ng sáº£n Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ há»— trá»£ báº¡n tá»‘t nháº¥t! ğŸ˜Š"""
            
            st.session_state.messages.append({"role": "assistant", "content": polite_refusal})
            st.markdown(f'<div class="assistant-message">{polite_refusal}</div>', 
                       unsafe_allow_html=True)
            return
        
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.markdown(f'<div class="user-message">{prompt}</div>', unsafe_allow_html=True)
        
        # Process with VBPL if available
        if vbpl_enabled and is_vbpl_available():
            with st.spinner("ğŸ¤” Äang phÃ¢n tÃ­ch cÃ¢u há»i vá»›i VBPL database..."):
                
                vbpl_result = process_with_vbpl(prompt)
                
                if vbpl_result.get('success'):
                    # Successful VBPL response
                    response = vbpl_result['response']
                    
                    # Display response
                    st.markdown(f'<div class="assistant-message">{response}</div>', 
                               unsafe_allow_html=True)
                    
                    # Show detailed results
                    if vbpl_result.get('sources'):
                        show_vbpl_results_details(vbpl_result)
                    
                    # Update token stats (estimate)
                    input_tokens = count_tokens(prompt)
                    output_tokens = count_tokens(response)
                    update_stats(input_tokens, output_tokens, selected_model)
                    
                else:
                    # VBPL failed, show fallback response
                    response = vbpl_result['response']
                    st.markdown(f'<div class="assistant-message">{response}</div>', 
                               unsafe_allow_html=True)
        
        else:
            # Fallback when VBPL not available
            fallback_response = """ğŸ—„ï¸ **CÆ¡ sá»Ÿ dá»¯ liá»‡u VBPL khÃ´ng kháº£ dá»¥ng**

Äá»ƒ cÃ³ thÃ´ng tin chÃ­nh xÃ¡c nháº¥t vá» váº¥n Ä‘á» nÃ y, báº¡n vui lÃ²ng:

1. **Tham kháº£o trá»±c tiáº¿p** táº¡i thuvienphapluat.vn
2. **LiÃªn há»‡** Sá»Ÿ TÃ i nguyÃªn vÃ  MÃ´i trÆ°á»ng Ä‘á»‹a phÆ°Æ¡ng
3. **Tham kháº£o** Luáº­t KhoÃ¡ng sáº£n hiá»‡n hÃ nh vÃ  cÃ¡c nghá»‹ Ä‘á»‹nh hÆ°á»›ng dáº«n

ğŸ’¡ **Gá»£i Ã½**: Äá»ƒ sá»­ dá»¥ng tÃ­nh nÄƒng tÃ¬m kiáº¿m database chÃ­nh xÃ¡c, vui lÃ²ng cung cáº¥p file `vbpl.db`."""
            
            st.markdown(f'<div class="assistant-message">{fallback_response}</div>', 
                       unsafe_allow_html=True)
        
        # Add response to history
        st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()