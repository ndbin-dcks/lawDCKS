import streamlit as st
from openai import OpenAI
import requests
import json
from datetime import datetime
import re
from urllib.parse import quote
import time
import os
import tiktoken

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="üèîÔ∏è Tr·ª£ l√Ω Ph√°p ch·∫ø Kho√°ng s·∫£n Vi·ªát Nam",
    page_icon="‚öñÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Pricing cho c√°c models OpenAI (USD per 1K tokens)
MODEL_PRICING = {
    "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002},
    "gpt-4": {"input": 0.03, "output": 0.06},
    "gpt-4-turbo": {"input": 0.01, "output": 0.03},
    "gpt-4-turbo-preview": {"input": 0.01, "output": 0.03}
}

class TokenCounter:
    """L·ªõp ƒë·∫øm token v√† t√≠nh chi ph√≠"""
    
    def __init__(self):
        self.reset_stats()
    
    def reset_stats(self):
        """Reset th·ªëng k√™ v·ªÅ 0"""
        if "token_stats" not in st.session_state:
            st.session_state.token_stats = {
                "total_input_tokens": 0,
                "total_output_tokens": 0,
                "total_cost": 0.0,
                "session_start": datetime.now(),
                "request_count": 0
            }
    
    def count_tokens(self, text, model="gpt-3.5-turbo"):
        """ƒê·∫øm s·ªë token trong text"""
        try:
            encoding = tiktoken.encoding_for_model(model)
            return len(encoding.encode(str(text)))
        except:
            # Fallback estimation: ~4 characters per token
            return len(str(text)) // 4
    
    def calculate_cost(self, input_tokens, output_tokens, model):
        """T√≠nh chi ph√≠ d·ª±a tr√™n s·ªë token"""
        if model not in MODEL_PRICING:
            model = "gpt-3.5-turbo"  # Default fallback
        
        pricing = MODEL_PRICING[model]
        input_cost = (input_tokens / 1000) * pricing["input"]
        output_cost = (output_tokens / 1000) * pricing["output"]
        return input_cost + output_cost
    
    def update_stats(self, input_tokens, output_tokens, model):
        """C·∫≠p nh·∫≠t th·ªëng k√™"""
        cost = self.calculate_cost(input_tokens, output_tokens, model)
        
        st.session_state.token_stats["total_input_tokens"] += input_tokens
        st.session_state.token_stats["total_output_tokens"] += output_tokens
        st.session_state.token_stats["total_cost"] += cost
        st.session_state.token_stats["request_count"] += 1
    
    def get_stats_display(self):
        """L·∫•y th·ªëng k√™ ƒë·ªÉ hi·ªÉn th·ªã"""
        stats = st.session_state.token_stats
        total_tokens = stats["total_input_tokens"] + stats["total_output_tokens"]
        
        return {
            "total_tokens": total_tokens,
            "input_tokens": stats["total_input_tokens"],
            "output_tokens": stats["total_output_tokens"],
            "total_cost_usd": stats["total_cost"],
            "total_cost_vnd": stats["total_cost"] * 24000,  # Estimate VND rate
            "requests": stats["request_count"],
            "session_duration": datetime.now() - stats["session_start"]
        }

# Kh·ªüi t·∫°o token counter
@st.cache_resource
def get_token_counter():
    return TokenCounter()

token_counter = get_token_counter()

# H√†m ƒë·ªçc n·ªôi dung t·ª´ file vƒÉn b·∫£n v·ªõi fallback cho chuy√™n ng√†nh kho√°ng s·∫£n
def rfile(name_file):
    try:
        with open(name_file, "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        # Fallback content chuy√™n bi·ªát cho kho√°ng s·∫£n
        fallback_content = {
            "00.xinchao.txt": "‚öñÔ∏è Tr·ª£ l√Ω Ph√°p ch·∫ø Kho√°ng s·∫£n Vi·ªát Nam",
            "01.system_trainning.txt": """S·∫øp l√† chuy√™n gia ph√°p ch·∫ø v·ªÅ qu·∫£n l√Ω nh√† n∆∞·ªõc trong lƒ©nh v·ª±c kho√°ng s·∫£n t·∫°i Vi·ªát Nam. S·∫øp c√≥ ki·∫øn th·ª©c s√¢u r·ªông v·ªÅ:

üèîÔ∏è Lƒ®NH V·ª∞C CHUY√äN M√îN:
- Lu·∫≠t Kho√°ng s·∫£n 2017 v√† c√°c vƒÉn b·∫£n h∆∞·ªõng d·∫´n thi h√†nh
- Ngh·ªã ƒë·ªãnh v·ªÅ qu·∫£n l√Ω ho·∫°t ƒë·ªông kho√°ng s·∫£n
- Th√¥ng t∆∞ c·ªßa B·ªô T√†i nguy√™n v√† M√¥i tr∆∞·ªùng
- Quy ƒë·ªãnh v·ªÅ thƒÉm d√≤, khai th√°c kho√°ng s·∫£n
- C·∫•p ph√©p ho·∫°t ƒë·ªông kho√°ng s·∫£n
- Thu·∫ø, ph√≠ li√™n quan ƒë·∫øn kho√°ng s·∫£n
- B·∫£o v·ªá m√¥i tr∆∞·ªùng trong ho·∫°t ƒë·ªông kho√°ng s·∫£n
- X·ª≠ ph·∫°t vi ph·∫°m h√†nh ch√≠nh trong lƒ©nh v·ª±c kho√°ng s·∫£n

‚öñÔ∏è NGUY√äN T·∫ÆC L√ÄM VI·ªÜC:
1. Ch·ªâ t·∫≠p trung v√†o c√°c v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn kho√°ng s·∫£n ·ªü Vi·ªát Nam
2. ƒê∆∞a ra th√¥ng tin ch√≠nh x√°c, d·∫´n chi·∫øu c·ª• th·ªÉ ƒëi·ªÅu kho·∫£n ph√°p lu·∫≠t
3. Gi·∫£i th√≠ch r√µ r√†ng, d·ªÖ hi·ªÉu cho c·∫£ chuy√™n gia v√† ng∆∞·ªùi d√¢n
4. Khi t√¨m ki·∫øm web, ∆∞u ti√™n ngu·ªìn ch√≠nh th·ªëng: portal.gov.vn, monre.gov.vn, thuvienphapluat.vn
5. T·ª´ ch·ªëi tr·∫£ l·ªùi c√°c c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn kho√°ng s·∫£n

üéØ C√ÅCH TR√çCH D·∫™N:
- Lu√¥n ghi r√µ t√™n vƒÉn b·∫£n ph√°p lu·∫≠t, ƒëi·ªÅu, kho·∫£n c·ª• th·ªÉ
- V√≠ d·ª•: "Theo ƒêi·ªÅu 15 Lu·∫≠t Kho√°ng s·∫£n 2017..."
- Khi c√≥ th√¥ng tin web: "D·ª±a theo th√¥ng tin t·ª´ [ngu·ªìn ch√≠nh th·ªëng]..."

QUAN TR·ªåNG: Ch·ªâ tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ kho√°ng s·∫£n. N·∫øu c√¢u h·ªèi kh√¥ng li√™n quan, h√£y l·ªãch s·ª± chuy·ªÉn h∆∞·ªõng v·ªÅ lƒ©nh v·ª±c chuy√™n m√¥n.""",
            
            "02.assistant.txt": """Xin ch√†o! ‚öñÔ∏è 

Em l√† Tr·ª£ l√Ω Ph√°p ch·∫ø chuy√™n v·ªÅ **Qu·∫£n l√Ω Nh√† n∆∞·ªõc trong lƒ©nh v·ª±c Kho√°ng s·∫£n t·∫°i Vi·ªát Nam**.

üèîÔ∏è **Em c√≥ th·ªÉ h·ªó tr·ª£ S·∫øp v·ªÅ:**

‚úÖ **Ph√°p lu·∫≠t Kho√°ng s·∫£n:**
   ‚Ä¢ Lu·∫≠t Kho√°ng s·∫£n 2017 v√† vƒÉn b·∫£n h∆∞·ªõng d·∫´n
   ‚Ä¢ Ngh·ªã ƒë·ªãnh, Th√¥ng t∆∞ c·ªßa B·ªô TN&MT
   ‚Ä¢ Quy ƒë·ªãnh v·ªÅ thƒÉm d√≤, khai th√°c

‚úÖ **Th·ªß t·ª•c h√†nh ch√≠nh:**
   ‚Ä¢ C·∫•p gi·∫•y ph√©p thƒÉm d√≤, khai th√°c
   ‚Ä¢ H·ªì s∆°, quy tr√¨nh xin ph√©p
   ‚Ä¢ Th·ªùi h·∫°n, ƒëi·ªÅu ki·ªán c·∫•p ph√©p

‚úÖ **Thu·∫ø, ph√≠ Kho√°ng s·∫£n:**
   ‚Ä¢ Thu·∫ø t√†i nguy√™n
   ‚Ä¢ Ph√≠ thƒÉm d√≤, khai th√°c
   ‚Ä¢ Ti·ªÅn c·∫•p quy·ªÅn khai th√°c

‚úÖ **X·ª≠ ph·∫°t vi ph·∫°m:**
   ‚Ä¢ Ngh·ªã ƒë·ªãnh x·ª≠ ph·∫°t vi ph·∫°m h√†nh ch√≠nh
   ‚Ä¢ M·ª©c ph·∫°t, bi·ªán ph√°p kh·∫Øc ph·ª•c

‚úÖ **B·∫£o v·ªá m√¥i tr∆∞·ªùng:**
   ‚Ä¢ ƒê√°nh gi√° t√°c ƒë·ªông m√¥i tr∆∞·ªùng
   ‚Ä¢ Ph·ª•c h·ªìi m√¥i tr∆∞·ªùng sau khai th√°c

**üéØ L∆∞u √Ω:** Em ch·ªâ t∆∞ v·∫•n v·ªÅ lƒ©nh v·ª±c Kho√°ng s·∫£n. ƒê·ªëi v·ªõi c√°c v·∫•n ƒë·ªÅ kh√°c, S·∫øp vui l√≤ng tham kh·∫£o chuy√™n gia ph√π h·ª£p.

**S·∫øp c√≥ th·∫Øc m·∫Øc g√¨ v·ªÅ ph√°p lu·∫≠t Kho√°ng s·∫£n kh√¥ng?** ü§î""",
            
            "module_chatgpt.txt": "gpt-3.5-turbo"
        }
        return fallback_content.get(name_file, f"N·ªôi dung m·∫∑c ƒë·ªãnh cho {name_file}")

# L·ªõp x·ª≠ l√Ω t√¨m ki·∫øm web chuy√™n bi·ªát cho kho√°ng s·∫£n
class MineralLawSearcher:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # C√°c ngu·ªìn ∆∞u ti√™n cho kho√°ng s·∫£n
        self.priority_domains = [
            'thuvienphapluat.vn',
            'monre.gov.vn', 
            'portal.gov.vn',
            'moj.gov.vn',
            'mic.gov.vn'
        ]
    
    def search(self, query, max_results=3):
        """T√¨m ki·∫øm chuy√™n bi·ªát cho ph√°p lu·∫≠t kho√°ng s·∫£n"""
        try:
            # Th√™m t·ª´ kh√≥a chuy√™n ng√†nh
            enhanced_query = f"{query} kho√°ng s·∫£n Vi·ªát Nam"
            
            # Th·ª≠ t√¨m tr√™n thuvienphapluat.vn tr∆∞·ªõc
            results = self._search_legal_database(enhanced_query, max_results)
            
            if not results:
                # Fallback sang DuckDuckGo v·ªõi site filter
                results = self._search_duckduckgo_legal(enhanced_query, max_results)
            
            return results[:max_results]
            
        except Exception as e:
            st.error(f"L·ªói t√¨m ki·∫øm ph√°p lu·∫≠t: {str(e)}")
            return self._get_legal_fallback(query)
    
    def _search_legal_database(self, query, max_results):
        """T√¨m ki·∫øm tr√™n c∆° s·ªü d·ªØ li·ªáu ph√°p lu·∫≠t"""
        # Simulation c·ªßa search tr√™n thuvienphapluat.vn
        # Trong th·ª±c t·∫ø c√≥ th·ªÉ t√≠ch h·ª£p API c·ªßa h·ªç
        results = []
        
        try:
            # DuckDuckGo v·ªõi site filter
            site_query = f"site:thuvienphapluat.vn {query}"
            results = self._search_duckduckgo_basic(site_query, max_results)
            
            # ƒê√°nh d·∫•u ngu·ªìn ∆∞u ti√™n
            for result in results:
                result['source'] = 'Th∆∞ vi·ªán Ph√°p lu·∫≠t'
                result['priority'] = True
                
        except:
            pass
            
        return results
    
    def _search_duckduckgo_legal(self, query, max_results):
        """DuckDuckGo search v·ªõi focus ph√°p lu·∫≠t"""
        try:
            legal_query = f"{query} site:gov.vn OR site:thuvienphapluat.vn"
            return self._search_duckduckgo_basic(legal_query, max_results)
        except:
            return []
    
    def _search_duckduckgo_basic(self, query, max_results):
        """DuckDuckGo c∆° b·∫£n"""
        try:
            params = {
                'q': query,
                'format': 'json',
                'no_html': '1',
                'skip_disambig': '1'
            }
            
            response = self.session.get(
                "https://api.duckduckgo.com/", 
                params=params, 
                timeout=10
            )
            
            if response.status_code != 200:
                return []
                
            data = response.json()
            results = []
            
            # Abstract answer
            if data.get('Abstract') and len(data['Abstract']) > 50:
                results.append({
                    'title': data.get('AbstractText', 'Th√¥ng tin ph√°p lu·∫≠t')[:100],
                    'content': data.get('Abstract'),
                    'url': data.get('AbstractURL', ''),
                    'source': data.get('AbstractSource', 'DuckDuckGo'),
                    'priority': False
                })
            
            # Related topics
            for topic in data.get('RelatedTopics', [])[:max_results-len(results)]:
                if isinstance(topic, dict) and topic.get('Text'):
                    results.append({
                        'title': topic.get('Text', '')[:80] + '...',
                        'content': topic.get('Text', ''),
                        'url': topic.get('FirstURL', ''),
                        'source': 'DuckDuckGo',
                        'priority': False
                    })
            
            return results
            
        except Exception as e:
            return []
    
    def _get_legal_fallback(self, query):
        """K·∫øt qu·∫£ d·ª± ph√≤ng cho t√¨m ki·∫øm ph√°p lu·∫≠t"""
        return [{
            'title': 'Kh√¥ng th·ªÉ t√¨m ki·∫øm ph√°p lu·∫≠t tr·ª±c tuy·∫øn',
            'content': f'Hi·ªán t·∫°i kh√¥ng th·ªÉ t√¨m ki·∫øm th√¥ng tin ph√°p lu·∫≠t cho: "{query}". Em s·∫Ω tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c ph√°p lu·∫≠t kho√°ng s·∫£n c√≥ s·∫µn.',
            'url': 'https://thuvienphapluat.vn',
            'source': 'H·ªá th·ªëng',
            'priority': False
        }]

# Kh·ªüi t·∫°o mineral law searcher
@st.cache_resource
def get_mineral_searcher():
    return MineralLawSearcher()

mineral_searcher = get_mineral_searcher()

def is_mineral_related(message):
    """Ki·ªÉm tra c√¢u h·ªèi c√≥ li√™n quan ƒë·∫øn kho√°ng s·∫£n kh√¥ng"""
    mineral_keywords = [
        # T·ª´ kh√≥a ch√≠nh
        'kho√°ng s·∫£n', 'khai th√°c', 'thƒÉm d√≤', 'ƒë√°', 'c√°t', 's·ªèi',
        'than', 'qu·∫∑ng', 'kim lo·∫°i', 'phi kim lo·∫°i', 'kho√°ng',
        
        # Ph√°p lu·∫≠t
        'lu·∫≠t kho√°ng s·∫£n', 'gi·∫•y ph√©p', 'c·∫•p ph√©p', 'thu·∫ø t√†i nguy√™n',
        'ph√≠ thƒÉm d√≤', 'ti·ªÅn c·∫•p quy·ªÅn', 'vi ph·∫°m h√†nh ch√≠nh',
        
        # C∆° quan
        'b·ªô t√†i nguy√™n', 's·ªü t√†i nguy√™n', 'monre', 'tn&mt',
        
        # Ho·∫°t ƒë·ªông
        'm·ªè', 'm·ªè ƒë√°', 'm·ªè c√°t', 'm·ªè than', 'quarry', 'mining'
    ]
    
    message_lower = message.lower()
    return any(keyword in message_lower for keyword in mineral_keywords)

def should_search_legal_web(message):
    """Ki·ªÉm tra c√≥ c·∫ßn t√¨m ki·∫øm ph√°p lu·∫≠t tr√™n web"""
    search_indicators = [
        'm·ªõi nh·∫•t', 'c·∫≠p nh·∫≠t', 'hi·ªán h√†nh', 'ban h√†nh', 's·ª≠a ƒë·ªïi',
        'b·ªï sung', 'thay th·∫ø', 'c√≥ hi·ªáu l·ª±c', 'quy ƒë·ªãnh m·ªõi',
        'ngh·ªã ƒë·ªãnh', 'th√¥ng t∆∞', 'lu·∫≠t', 'ph√°p lu·∫≠t'
    ]
    
    message_lower = message.lower()
    return (is_mineral_related(message) and 
            any(indicator in message_lower for indicator in search_indicators))

def create_legal_enhanced_prompt(user_message, search_results):
    """T·∫°o prompt v·ªõi th√¥ng tin ph√°p lu·∫≠t t√¨m ki·∫øm"""
    if not search_results or not any(r.get('content') for r in search_results):
        return user_message
    
    legal_info = "\n\n=== TH√îNG TIN PH√ÅP LU·∫¨T T√åM KI·∫æM ===\n"
    for i, result in enumerate(search_results, 1):
        if result.get('content'):
            priority_mark = "‚≠ê " if result.get('priority') else ""
            legal_info += f"\n{priority_mark}Ngu·ªìn {i} ({result['source']}):\n"
            legal_info += f"Ti√™u ƒë·ªÅ: {result['title']}\n"
            legal_info += f"N·ªôi dung: {result['content'][:500]}...\n"
            if result.get('url'):
                legal_info += f"URL: {result['url']}\n"
            legal_info += "---\n"
    
    legal_info += "\nH∆∞·ªõng d·∫´n: S·ª≠ d·ª•ng th√¥ng tin ph√°p lu·∫≠t tr√™n ƒë·ªÉ tr·∫£ l·ªùi. "
    legal_info += "∆Øu ti√™n ngu·ªìn c√≥ ‚≠ê. H√£y tr√≠ch d·∫´n c·ª• th·ªÉ ƒëi·ªÅu, kho·∫£n n·∫øu c√≥.\n"
    legal_info += "=== K·∫æT TH√öC TH√îNG TIN PH√ÅP LU·∫¨T ===\n\n"
    
    return legal_info + f"C√¢u h·ªèi v·ªÅ kho√°ng s·∫£n: {user_message}"

# Main UI
def main():
    # Custom CSS cho giao di·ªán bot tr√°i, user ph·∫£i
    st.markdown(
        """
        <style>
        .assistant-message {
            background: #f0f8ff;
            padding: 15px;
            border-radius: 15px;
            margin: 10px 0;
            max-width: 80%;
            border-left: 4px solid #4CAF50;
        }
        .assistant-message::before { 
            content: "‚öñÔ∏è Tr·ª£ l√Ω Ph√°p ch·∫ø: "; 
            font-weight: bold; 
            color: #2E7D32;
        }
        
        .user-message {
            background: #e3f2fd;
            padding: 15px;
            border-radius: 15px;
            margin: 10px 0 10px auto;
            max-width: 80%;
            text-align: right;
            border-right: 4px solid #2196F3;
        }
        .user-message::before { 
            content: "üë§ S·∫øp: "; 
            font-weight: bold; 
            color: #1976D2;
        }
        
        .stats-box {
            background: #f5f5f5;
            padding: 10px;
            border-radius: 8px;
            border: 1px solid #ddd;
            margin: 5px 0;
        }
        
        .cost-highlight {
            color: #d32f2f;
            font-weight: bold;
        }
        
        .token-highlight {
            color: #1976d2;
            font-weight: bold;
        }
        </style>
        """,
        unsafe_allow_html=True
    )
    
    # Header
    st.markdown(
        """
        <div style="text-align: center; padding: 20px; background: linear-gradient(90deg, #2E7D32, #4CAF50); border-radius: 10px; margin-bottom: 20px;">
            <h1 style="color: white; margin: 0;">‚öñÔ∏è Tr·ª£ l√Ω Ph√°p ch·∫ø Kho√°ng s·∫£n</h1>
            <p style="color: #E8F5E8; margin: 5px 0 0 0;">Chuy√™n gia t∆∞ v·∫•n Qu·∫£n l√Ω Nh√† n∆∞·ªõc v·ªÅ Kho√°ng s·∫£n t·∫°i Vi·ªát Nam</p>
        </div>
        """,
        unsafe_allow_html=True
    )
    
    # Sidebar v·ªõi th·ªëng k√™ chi ti·∫øt
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è C√†i ƒë·∫∑t h·ªá th·ªëng")
        
        # Toggle web search cho ph√°p lu·∫≠t
        legal_search_enabled = st.toggle("üîç T√¨m ki·∫øm ph√°p lu·∫≠t online", value=True)
        
        # Model selection
        model_options = ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview"]
        selected_model = st.selectbox("ü§ñ Ch·ªçn model AI:", model_options, index=0)
        
        # Temperature setting
        temperature = st.slider("üå°Ô∏è ƒê·ªô s√°ng t·∫°o (Temperature):", 0.0, 1.0, 0.3, 0.1,
                               help="0.0 = Ch√≠nh x√°c, 1.0 = S√°ng t·∫°o")
        
        st.markdown("---")
        
        # Th·ªëng k√™ token v√† chi ph√≠
        st.markdown("### üìä Th·ªëng k√™ s·ª≠ d·ª•ng")
        
        stats = token_counter.get_stats_display()
        
        # Token stats
        st.markdown('<div class="stats-box">', unsafe_allow_html=True)
        st.metric("üéØ T·ªïng Token", f"{stats['total_tokens']:,}")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("üì• Input", f"{stats['input_tokens']:,}")
        with col2:
            st.metric("üì§ Output", f"{stats['output_tokens']:,}")
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Cost stats
        st.markdown('<div class="stats-box">', unsafe_allow_html=True)
        st.metric("üí∞ Chi ph√≠ (USD)", f"${stats['total_cost_usd']:.4f}")
        st.metric("üí∏ Chi ph√≠ (VND)", f"{stats['total_cost_vnd']:,.0f}ƒë")
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Session stats
        st.markdown('<div class="stats-box">', unsafe_allow_html=True)
        st.metric("üìû S·ªë l∆∞·ª£t h·ªèi", stats['requests'])
        duration = str(stats['session_duration']).split('.')[0]
        st.metric("‚è±Ô∏è Th·ªùi gian", duration)
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Reset button
        if st.button("üîÑ Reset th·ªëng k√™", use_container_width=True):
            token_counter.reset_stats()
            st.rerun()
        
        st.markdown("---")
        
        # Clear chat button
        if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
            st.session_state.messages = [
                {"role": "system", "content": rfile("01.system_trainning.txt")},
                {"role": "assistant", "content": rfile("02.assistant.txt")}
            ]
            st.rerun()
        
        st.markdown("---")
        st.markdown("### üìö Lƒ©nh v·ª±c chuy√™n m√¥n")
        st.markdown("‚Ä¢ Lu·∫≠t Kho√°ng s·∫£n 2017")
        st.markdown("‚Ä¢ Ngh·ªã ƒë·ªãnh h∆∞·ªõng d·∫´n")
        st.markdown("‚Ä¢ Th√¥ng t∆∞ B·ªô TN&MT")
        st.markdown("‚Ä¢ Th·ªß t·ª•c c·∫•p ph√©p")
        st.markdown("‚Ä¢ Thu·∫ø, ph√≠ kho√°ng s·∫£n")
        st.markdown("‚Ä¢ X·ª≠ ph·∫°t vi ph·∫°m")
        st.markdown("‚Ä¢ B·∫£o v·ªá m√¥i tr∆∞·ªùng")
    
    # Check API key
    if not st.secrets.get("OPENAI_API_KEY"):
        st.error("‚ùå Ch∆∞a c·∫•u h√¨nh OPENAI_API_KEY trong secrets!")
        st.stop()
    
    # Initialize OpenAI client
    try:
        client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    except Exception as e:
        st.error(f"‚ùå L·ªói kh·ªüi t·∫°o OpenAI client: {str(e)}")
        st.stop()
    
    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": rfile("01.system_trainning.txt")},
            {"role": "assistant", "content": rfile("02.assistant.txt")}
        ]
    
    # Display chat history v·ªõi style t√πy ch·ªânh
    for message in st.session_state.messages:
        if message["role"] == "assistant":
            st.markdown(f'<div class="assistant-message">{message["content"]}</div>', 
                       unsafe_allow_html=True)
        elif message["role"] == "user":
            st.markdown(f'<div class="user-message">{message["content"]}</div>', 
                       unsafe_allow_html=True)
    
    # Chat input
    if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi v·ªÅ ph√°p lu·∫≠t kho√°ng s·∫£n..."):
        # Ki·ªÉm tra c√¢u h·ªèi c√≥ li√™n quan ƒë·∫øn kho√°ng s·∫£n kh√¥ng
        if not is_mineral_related(prompt):
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.markdown(f'<div class="user-message">{prompt}</div>', unsafe_allow_html=True)
            
            # Ph·∫£n h·ªìi t·ª´ ch·ªëi l·ªãch s·ª±
            polite_refusal = """Xin l·ªói, Em l√† tr·ª£ l√Ω chuy√™n v·ªÅ **ph√°p lu·∫≠t kho√°ng s·∫£n** t·∫°i Vi·ªát Nam. 

Em ch·ªâ c√≥ th·ªÉ t∆∞ v·∫•n v·ªÅ c√°c v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn:
- üèîÔ∏è Lu·∫≠t Kho√°ng s·∫£n v√† vƒÉn b·∫£n h∆∞·ªõng d·∫´n
- ‚öñÔ∏è Th·ªß t·ª•c c·∫•p ph√©p thƒÉm d√≤, khai th√°c
- üí∞ Thu·∫ø, ph√≠ li√™n quan ƒë·∫øn kho√°ng s·∫£n  
- üå± B·∫£o v·ªá m√¥i tr∆∞·ªùng trong ho·∫°t ƒë·ªông kho√°ng s·∫£n
- ‚ö†Ô∏è X·ª≠ ph·∫°t vi ph·∫°m h√†nh ch√≠nh

S·∫øp c√≥ th·ªÉ h·ªèi Em v·ªÅ nh·ªØng v·∫•n ƒë·ªÅ n√†y kh√¥ng? V√≠ d·ª•:
- "Th·ªß t·ª•c xin ph√©p khai th√°c ƒë√° nh∆∞ th·∫ø n√†o?"
- "M·ª©c thu·∫ø t√†i nguy√™n hi·ªán t·∫°i ra sao?"
- "Vi ph·∫°m trong khai th√°c kho√°ng s·∫£n b·ªã ph·∫°t nh∆∞ th·∫ø n√†o?"

Em s·∫µn s√†ng h·ªó tr·ª£ S·∫øp! üòä"""
            
            st.session_state.messages.append({"role": "assistant", "content": polite_refusal})
            st.markdown(f'<div class="assistant-message">{polite_refusal}</div>', 
                       unsafe_allow_html=True)
            return
        
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.markdown(f'<div class="user-message">{prompt}</div>', unsafe_allow_html=True)
        
        # Process response
        with st.spinner("ü§î ƒêang ph√¢n t√≠ch c√¢u h·ªèi ph√°p lu·∫≠t..."):
            # Check if legal web search is needed
            search_results = []
            final_prompt = prompt
            
            if legal_search_enabled and should_search_legal_web(prompt):
                with st.status("üîç ƒêang t√¨m ki·∫øm vƒÉn b·∫£n ph√°p lu·∫≠t...", expanded=False) as status:
                    search_results = mineral_searcher.search(prompt, max_results=3)
                    
                    if search_results and any(r.get('content') for r in search_results):
                        priority_count = sum(1 for r in search_results if r.get('priority'))
                        st.success(f"‚úÖ T√¨m th·∫•y {len(search_results)} k·∫øt qu·∫£ ({priority_count} ngu·ªìn ∆∞u ti√™n)")
                        
                        for i, result in enumerate(search_results, 1):
                            if result.get('content'):
                                priority_mark = "‚≠ê " if result.get('priority') else ""
                                st.write(f"**{priority_mark}{i}. {result['source']}:** {result['title'][:50]}...")
                        
                        final_prompt = create_legal_enhanced_prompt(prompt, search_results)
                        status.update(label="‚úÖ Ho√†n t·∫•t t√¨m ki·∫øm ph√°p lu·∫≠t", state="complete", expanded=False)
                    else:
                        status.update(label="‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y vƒÉn b·∫£n li√™n quan", state="complete", expanded=False)
            
            # ƒê·∫øm input tokens
            messages_for_api = [
                msg for msg in st.session_state.messages[:-1] 
                if msg["role"] != "system" or msg == st.session_state.messages[0]
            ]
            messages_for_api.append({"role": "user", "content": final_prompt})
            
            input_text = "\n".join([msg["content"] for msg in messages_for_api])
            input_tokens = token_counter.count_tokens(input_text, selected_model)
            
            # Generate AI response
            try:
                response = ""
                
                stream = client.chat.completions.create(
                    model=selected_model,
                    messages=messages_for_api,
                    stream=True,
                    temperature=temperature,
                    max_tokens=2000
                )
                
                # Container cho response
                response_container = st.empty()
                
                for chunk in stream:
                    if chunk.choices and chunk.choices[0].delta.content:
                        response += chunk.choices[0].delta.content
                        # Update response hi·ªÉn th·ªã v·ªõi style
                        response_container.markdown(
                            f'<div class="assistant-message">{response}‚ñå</div>', 
                            unsafe_allow_html=True
                        )
                
                # Final response
                response_container.markdown(
                    f'<div class="assistant-message">{response}</div>', 
                    unsafe_allow_html=True
                )
                
                # ƒê·∫øm output tokens v√† c·∫≠p nh·∫≠t stats
                output_tokens = token_counter.count_tokens(response, selected_model)
                token_counter.update_stats(input_tokens, output_tokens, selected_model)
                
                # Hi·ªÉn th·ªã stats c·ªßa request n√†y
                with st.expander("üìä Th·ªëng k√™ request n√†y"):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Input tokens", f"{input_tokens:,}")
                    with col2:
                        st.metric("Output tokens", f"{output_tokens:,}")
                    with col3:
                        cost = token_counter.calculate_cost(input_tokens, output_tokens, selected_model)
                        st.metric("Chi ph√≠", f"${cost:.4f}")
                
            except Exception as e:
                error_msg = f"‚ùå L·ªói h·ªá th·ªëng: {str(e)}"
                st.markdown(f'<div class="assistant-message">{error_msg}</div>', 
                           unsafe_allow_html=True)
                response = error_msg
        
        # Add assistant response to history
        st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()